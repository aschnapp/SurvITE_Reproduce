{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aschnapp/SurvITE_Reproduce/blob/main/SurvITE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfhrg53y3U3G",
        "outputId": "2a02e64d-1d95-4a1e-9e6f-5647faf18a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-survival\n",
            "  Downloading scikit_survival-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-survival) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn<1.3,>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from scikit-survival) (1.2.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.9/dist-packages (from scikit-survival) (2.8.4)\n",
            "Requirement already satisfied: ecos in /usr/local/lib/python3.9/dist-packages (from scikit-survival) (2.0.12)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.9/dist-packages (from scikit-survival) (1.5.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from scikit-survival) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from scikit-survival) (1.24.2)\n",
            "Requirement already satisfied: osqp!=0.6.0,!=0.6.1 in /usr/local/lib/python3.9/dist-packages (from scikit-survival) (0.6.2.post0)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.9/dist-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival) (0.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->scikit-survival) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->scikit-survival) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<1.3,>=1.2.0->scikit-survival) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.5->scikit-survival) (1.16.0)\n",
            "Installing collected packages: scikit-survival\n",
            "Successfully installed scikit-survival-0.20.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.9/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from tf_slim) (1.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-survival\n",
        "!pip install tf_slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyZzTKvk3Z2U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "def f_get_minibatch(mb_size, x1, x2=None, x3=None, x4=None, x5=None):\n",
        "    idx = range(np.shape(x1)[0])\n",
        "    idx = random.sample(idx, mb_size)\n",
        "    \n",
        "    if x2 is None:\n",
        "        return x1[idx].astype(float)\n",
        "    if x3 is None:\n",
        "        return x1[idx].astype(float), x2[idx].astype(float)\n",
        "    if x4 is None:\n",
        "        return x1[idx].astype(float), x2[idx].astype(float), x3[idx].astype(float)\n",
        "    if x5 is None:\n",
        "        return x1[idx].astype(float), x2[idx].astype(float), x3[idx].astype(float), x4[idx].astype(float)\n",
        "    \n",
        "    return x1[idx].astype(float), x2[idx].astype(float), x3[idx].astype(float), x4[idx].astype(float), x5[idx].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuucWY5H3k7_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "_EPSILON = 1e-08\n",
        "\n",
        "\n",
        "################################\n",
        "##### USER-DEFINED FUNCTIONS\n",
        "def log(x):\n",
        "    return tf.log(x + _EPSILON)\n",
        "\n",
        "def div(x, y):\n",
        "    return tf.compat.v1.div(x, (y + _EPSILON))\n",
        "\n",
        "################################\n",
        "##### IPM TERMS\n",
        "def pdist2sq(X,Y):\n",
        "    \"\"\" Computes the squared Euclidean distance between all pairs x in X, y in Y \"\"\"\n",
        "    C = -2*tf.matmul(X,tf.transpose(Y))\n",
        "    nx = tf.compat.v1.reduce_sum(tf.square(X),1,keep_dims=True)\n",
        "    ny = tf.compat.v1.reduce_sum(tf.square(Y),1,keep_dims=True)\n",
        "    D = (C + tf.transpose(ny)) + nx\n",
        "    return D\n",
        "\n",
        "\n",
        "# def mmd2_lin(X1,X2,p=0.5):\n",
        "#     ''' Linear MMD '''\n",
        "#     mean1 = tf.reduce_mean(X1,reduction_indices=0)\n",
        "#     mean2 = tf.reduce_mean(X2,reduction_indices=0)\n",
        "\n",
        "#     mmd = tf.compat.v1.reduce_sum(tf.square(2.0*p*mean1 - 2.0*(1.0-p)*mean2))\n",
        "\n",
        "#     return mmd\n",
        "\n",
        "# def mmd2_rbf(X1,X2,p=0.5,sig=0.1):\n",
        "#     \"\"\" Computes the l2-RBF MMD for X1 vs X2 \"\"\"\n",
        "#     K11 = tf.exp(-pdist2sq(X1,X1)/tf.square(sig))\n",
        "#     K12 = tf.exp(-pdist2sq(X1,X2)/tf.square(sig))\n",
        "#     K22 = tf.exp(-pdist2sq(X2,X2)/tf.square(sig))\n",
        "\n",
        "#     m = tf.compat.v1.to_float(tf.shape(X1)[0])\n",
        "#     n = tf.compat.v1.to_float(tf.shape(X2)[0])\n",
        "\n",
        "#     mmd = tf.square(1.0-p)/(m*(m-1.0))*(tf.compat.v1.reduce_sum(K11)-m)\n",
        "#     mmd = mmd + tf.square(p)/(n*(n-1.0))*(tf.compat.v1.reduce_sum(K22)-n)\n",
        "#     mmd = mmd - 2.0*p*(1.0-p)/(m*n)*tf.compat.v1.reduce_sum(K12)\n",
        "#     mmd = 4.0*mmd\n",
        "\n",
        "#     return mmd\n",
        "\n",
        "def mmd2_lin(X1,X2,W1=None,W2=None,p=0.5,weights=None):\n",
        "    ''' Linear MMD '''    \n",
        "    if (W1 is None) and (W2 is None):\n",
        "        W1 = tf.ones_like(X1[:,0])\n",
        "        W2 = tf.ones_like(X2[:,0])\n",
        "    \n",
        "    W1     = div(W1, tf.compat.v1.reduce_sum(W1))\n",
        "    W2     = div(W2, tf.compat.v1.reduce_sum(W2))\n",
        "    \n",
        "    W1     = tf.reshape(W1, [-1,1])\n",
        "    W2     = tf.reshape(W2, [-1,1])\n",
        "        \n",
        "    mean1 = tf.compat.v1.reduce_sum(W1*X1, axis=0)\n",
        "    mean2 = tf.compat.v1.reduce_sum(W2*X2, axis=0)\n",
        "    \n",
        "    mmd = tf.compat.v1.reduce_sum(tf.square(2.0*p*mean1 - 2.0*(1.0-p)*mean2))\n",
        "    \n",
        "    return mmd\n",
        "\n",
        "\n",
        "def wasserstein(X1,X2,W1=None,W2=None,p=0.5,lam=10,its=10): #,sq=False,backpropT=False):\n",
        "    \"\"\" Returns the Wasserstein distance between treatment groups \"\"\"    \n",
        "    n1 = tf.compat.v1.to_float(tf.shape(X1)[0])\n",
        "    n2 = tf.compat.v1.to_float(tf.shape(X2)[0])\n",
        "    \n",
        "    ''' Compute distance matrix'''\n",
        "    M = pdist2sq(X1,X2)\n",
        "        \n",
        "    #for now consider W1 and W2 is [None,] shape\n",
        "    if (W1 is None) and (W2 is None):\n",
        "        W1 = tf.ones_like(X1[:,0])\n",
        "        W2 = tf.ones_like(X2[:,0])\n",
        "    \n",
        "    W1     = div(W1, tf.compat.v1.reduce_sum(W1))\n",
        "    W2     = div(W2, tf.compat.v1.reduce_sum(W2))\n",
        "    \n",
        "    W1     = tf.reshape(W1, [-1,1])\n",
        "    W2     = tf.reshape(W2, [-1,1])\n",
        "    W_mask = tf.tile(W1, [1, n2]) * tf.tile(tf.transpose(W2), [n1, 1])\n",
        "    \n",
        "    ''' Estimate lambda and delta '''\n",
        "    M_mean = tf.compat.v1.reduce_sum(M*W_mask) #this becomes weighted average\n",
        "    \n",
        "    M_drop  = tf.nn.dropout(M, 10/(n1*n2))\n",
        "    delta   = tf.stop_gradient(tf.reduce_max(M))\n",
        "    eff_lam = tf.stop_gradient(lam/M_mean)\n",
        "\n",
        "    ''' Compute new distance matrix '''\n",
        "    Mt  = M\n",
        "    row = delta*tf.ones(tf.shape(M[0:1,:]))\n",
        "    col = tf.concat([delta*tf.ones(tf.shape(M[:,0:1])),tf.zeros((1,1))], axis=0)\n",
        "    Mt  = tf.concat([M,row], axis=0)\n",
        "    Mt  = tf.concat([Mt,col], axis=1)\n",
        "\n",
        "    ''' Compute marginal vectors '''        \n",
        "    a = tf.concat([p*tf.ones_like(X1[:,0:1])*W1, (1-p)*tf.ones((1,1))], axis=0)\n",
        "    b = tf.concat([(1-p)*tf.ones_like(X2[:,0:1])*W2, p*tf.ones((1,1))], axis=0)\n",
        "\n",
        "    ''' Compute kernel matrix'''\n",
        "    Mlam = eff_lam*Mt\n",
        "    K = tf.exp(-Mlam) + 1e-6 # added constant to avoid nan\n",
        "    U = K*Mt\n",
        "    ainvK = K/a\n",
        "\n",
        "    u = a\n",
        "    for i in range(0,its):\n",
        "        u = 1.0/(tf.matmul(ainvK,(b/tf.transpose(tf.matmul(tf.transpose(u),K)))))\n",
        "    v = b/(tf.transpose(tf.matmul(tf.transpose(u),K)))\n",
        "\n",
        "    T = u*(tf.transpose(v)*K)\n",
        "\n",
        "    E = T*Mt\n",
        "    D = 2*tf.compat.v1.reduce_sum(E)\n",
        "\n",
        "    return D #, Mlam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-4JtyZB3gA9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tf_slim as slim\n",
        "\n",
        "_EPSILON = 1e-08\n",
        "\n",
        "################################\n",
        "##### USER-DEFINED FUNCTIONS\n",
        "def log(x):\n",
        "    return tf.log(x + _EPSILON)\n",
        "\n",
        "def div(x, y):\n",
        "    return tf.compat.v1.div(x, (y + _EPSILON))\n",
        "\n",
        "\n",
        "##### NETWORK FUNCTIONS\n",
        "# removed reuse=tf.AUTO_REUSE\n",
        "def fcnet(x_, o_dim_, o_fn_, num_layers_=1, h_dim_=100, activation_fn=tf.nn.relu, keep_prob_=1.0, w_reg_=None, name='fcnet'):\n",
        "    '''\n",
        "        x_            : (2D-tensor) input\n",
        "        o_dim_        : (int) output dimension\n",
        "        o_type_       : (string) output type one of {'continuous', 'categorical', 'binary'}\n",
        "        num_layers_   : (int) # of hidden layers\n",
        "        activation_fn_: tf activation functions\n",
        "        reuse         : (bool) \n",
        "    '''\n",
        "    with tf.compat.v1.variable_scope(name):\n",
        "        if num_layers_ == 1:\n",
        "            out =  slim.layers.fully_connected(inputs=x_, num_outputs=o_dim_, activation_fn=o_fn_, weights_regularizer=w_reg_, scope='layer_out')\n",
        "        else:\n",
        "            for tmp_layer in range(num_layers_-1):\n",
        "                if tmp_layer == 0:\n",
        "                    net = x_\n",
        "                net = slim.layers.fully_connected(inputs=net, num_outputs=h_dim_, activation_fn=activation_fn, weights_regularizer=w_reg_, scope='layer_'+str(tmp_layer))\n",
        "                net = tf.compat.v1.nn.dropout(net, keep_prob=keep_prob_)\n",
        "            out =  slim.layers.fully_connected(inputs=net, num_outputs=o_dim_, activation_fn=o_fn_, weights_regularizer=w_reg_, scope='layer_out')  \n",
        "    return out\n",
        "\n",
        "\n",
        "################################\n",
        "##### NETWORK \n",
        "class SurvITE:\n",
        "    def __init__(self, sess, name, input_dims, network_settings):\n",
        "        self.sess               = sess\n",
        "        self.name               = name\n",
        "\n",
        "        ### INPUT DIMENSIONS\n",
        "        self.x_dim              = input_dims['x_dim']\n",
        "        self.t_max              = input_dims['t_max']\n",
        "        self.num_Event          = input_dims['num_Event'] #Without counting censoring.\n",
        "        \n",
        "\n",
        "        ### NETWORK HYPER-PARMETERS\n",
        "        self.z_dim              = network_settings['z_dim']  #PHI(X)\n",
        "        \n",
        "        self.h_dim1             = network_settings['h_dim1']  #PHI\n",
        "        self.h_dim2             = network_settings['h_dim2']  #Hypothesis\n",
        "        \n",
        "        self.num_layers1        = network_settings['num_layers1']\n",
        "        self.num_layers2        = network_settings['num_layers2']\n",
        " \n",
        "        self.active_fn          = network_settings['active_fn']\n",
        "        self.reg_scale          = network_settings['reg_scale']\n",
        "        \n",
        "        self.ipm_term           = network_settings['ipm_term']\n",
        "        self.is_treat           = network_settings['is_treat'] #boolean\n",
        "        self.is_smoothing       = network_settings['is_smoothing'] #boolean\n",
        "        \n",
        "        assert self.ipm_term in ['mmd_lin', 'wasserstein', 'no_ipm']\n",
        "\n",
        "        self.clipping_thres     = 10.\n",
        "\n",
        "        \n",
        "        self._build_net()\n",
        "\n",
        "\n",
        "    def _build_net(self):\n",
        "        with tf.compat.v1.variable_scope(self.name):\n",
        "            #### PLACEHOLDER DECLARATION\n",
        "            self.lr_rate        = tf.compat.v1.placeholder(tf.float32, [], name='learning_rate')\n",
        "            self.k_prob         = tf.compat.v1.placeholder(tf.float32, [], name='keep_probability')   #keeping rate\n",
        "            self.alpha          = tf.compat.v1.placeholder(tf.float32, [], name='alpha')\n",
        "            self.beta           = tf.compat.v1.placeholder(tf.float32, [], name='beta')\n",
        "            self.gamma          = tf.compat.v1.placeholder(tf.float32, [], name='gamma')\n",
        "\n",
        "            self.x              = tf.compat.v1.placeholder(tf.float32, shape=[None, self.x_dim], name='inputs')\n",
        "            self.y              = tf.compat.v1.placeholder(tf.float32, shape=[None, self.num_Event], name='labels')   #event/censoring label (censoring: the last column)\n",
        "            self.t              = tf.compat.v1.placeholder(tf.float32, shape=[None, 1], name='times')\n",
        "            self.a              = tf.compat.v1.placeholder(tf.float32, shape=[None, 1], name='treatment_assignments')\n",
        "            self.w              = tf.compat.v1.placeholder(tf.float32, shape=[None, self.t_max, 2], name='weights')            \n",
        "            \n",
        "            self.is_training    = tf.compat.v1.placeholder(tf.bool, name = 'train_test_indicator') #for batch_normalization\n",
        "            \n",
        "            self.mb_size        = tf.shape(self.x)[0]\n",
        "            \n",
        "            ### mask generation -- for easier computation for at-risk patients\n",
        "            tmp_range      = tf.cast(tf.expand_dims(tf.range(0, self.t_max, 1), axis=0), tf.float32)\n",
        "            self.mask1     = tf.cast(tf.equal(tmp_range, self.t), tf.float32)\n",
        "            self.mask2     = tf.cast(tf.less_equal(tmp_range, self.t), tf.float32)\n",
        "\n",
        "            y_expanded     = self.mask1 * self.y\n",
        "            \n",
        "            \n",
        "            #PHI(x)\n",
        "            self.z              = fcnet(\n",
        "                x_=self.x, o_dim_=self.z_dim, o_fn_=None, \n",
        "                num_layers_=self.num_layers1, h_dim_=self.h_dim1, activation_fn=self.active_fn, \n",
        "                keep_prob_=self.k_prob, name='encoder'\n",
        "            )\n",
        "            \n",
        "            \n",
        "            ###BATCH NORMALIZATION. (This follows the implementation of CFRNet)\n",
        "#             self.z = tf.math.l2_normalize(self.z, axis=0)\n",
        "            self.z = tf.compat.v1.layers.batch_normalization(self.z, training=self.is_training)\n",
        "            self.z = self.active_fn(self.z)\n",
        "            self.z = tf.compat.v1.nn.dropout(self.z, keep_prob=self.k_prob)\n",
        "\n",
        "\n",
        "            ### H(Z; A,T)\n",
        "            for m in range(self.t_max):\n",
        "                tmp_A1              = fcnet(\n",
        "                    x_=self.z, o_dim_=1, o_fn_=None, \n",
        "                    num_layers_=self.num_layers2, h_dim_=self.h_dim2, activation_fn=self.active_fn, \n",
        "                    keep_prob_=self.k_prob, name='hypothesis_A1_T{}'.format(m)\n",
        "                )\n",
        "                \n",
        "                if self.is_treat:\n",
        "                    tmp_A0              = fcnet(\n",
        "                        x_=self.z, o_dim_=1, o_fn_=None, \n",
        "                        num_layers_=self.num_layers2, h_dim_=self.h_dim2, activation_fn=self.active_fn, \n",
        "                        keep_prob_=self.k_prob, name='hypothesis_A0_T{}'.format(m)\n",
        "                    )\n",
        "                else:\n",
        "                    tmp_A0              = tf.zeros_like(tmp_A1)\n",
        "                    \n",
        "                if m == 0:\n",
        "                    self.logits_A1 = tmp_A1\n",
        "                    self.logits_A0 = tmp_A0\n",
        "                else:\n",
        "                    self.logits_A1 = tf.concat([self.logits_A1, tmp_A1], axis=1)\n",
        "                    self.logits_A0 = tf.concat([self.logits_A0, tmp_A0], axis=1)\n",
        "                    \n",
        "            \n",
        "            ### loss - IPM regularization\n",
        "            self.loss_IPM1 = 0. #treated\n",
        "            self.loss_IPM0 = 0. #not-treated\n",
        "\n",
        "            self.w_clipped = tf.clip_by_value(self.w, 0., self.clipping_thres, name='weights_clipped')\n",
        "\n",
        "            if self.ipm_term != 'no_ipm':\n",
        "                # for m in range(1, self.t_max):\n",
        "                for m in range(0, self.t_max):\n",
        "                    idx1             = tf.where(tf.equal(self.a[:, 0]*self.mask2[:, m], 1.))[:,0]\n",
        "                     \n",
        "                    if self.is_treat:\n",
        "                        idx0             = tf.where(tf.equal((1.-self.a[:, 0])*self.mask2[:, m], 1.))[:,0]\n",
        "                    \n",
        "                    \n",
        "                    if self.ipm_term == 'mmd_lin':\n",
        "                        self.loss_IPM1 += tf.cond(tf.equal(tf.size(idx1), 0),\n",
        "                                                  lambda: tf.constant(0, tf.float32),\n",
        "                                                  lambda: mmd2_lin(self.z, \n",
        "                                                                   tf.gather(self.z, idx1, axis=0), \n",
        "                                                                   tf.ones_like(self.z[:,0]), \n",
        "                                                                   tf.gather(self.w_clipped[:, m, 0], idx1, axis=0))\n",
        "                                                 )\n",
        "                        if self.is_treat:\n",
        "                            self.loss_IPM0 += tf.cond(tf.equal(tf.size(idx0), 0),\n",
        "                                                      lambda: tf.constant(0, tf.float32),\n",
        "                                                      lambda: mmd2_lin(self.z, \n",
        "                                                                          tf.gather(self.z, idx0, axis=0), \n",
        "                                                                          tf.ones_like(self.z[:,0]), \n",
        "                                                                          tf.gather(self.w_clipped[:, m, 1], idx0, axis=0))\n",
        "                                                     )\n",
        "                        \n",
        "                    elif self.ipm_term == 'wasserstein':\n",
        "                        self.loss_IPM1 += tf.cond(tf.equal(tf.size(idx1), 0),\n",
        "                                                  lambda: tf.constant(0, tf.float32),\n",
        "                                                  lambda: wasserstein(self.z, \n",
        "                                                                      tf.gather(self.z, idx1, axis=0), \n",
        "                                                                      tf.ones_like(self.z[:,0]), \n",
        "                                                                      tf.gather(self.w_clipped[:, m, 0], idx1, axis=0))\n",
        "                                                 )\n",
        "                        if self.is_treat:\n",
        "                            self.loss_IPM0 += tf.cond(tf.equal(tf.size(idx0), 0),\n",
        "                                                      lambda: tf.constant(0, tf.float32),\n",
        "                                                      lambda: wasserstein(self.z, \n",
        "                                                                          tf.gather(self.z, idx0, axis=0), \n",
        "                                                                          tf.ones_like(self.z[:,0]), \n",
        "                                                                          tf.gather(self.w_clipped[:, m, 1], idx0, axis=0))\n",
        "                                                     )\n",
        "            self.loss_IPM = self.loss_IPM1 + self.loss_IPM0\n",
        "\n",
        "\n",
        "\n",
        "            ### loss - smoothing regularization\n",
        "            self.loss_smoothing_A1 = 0. #treated\n",
        "            self.loss_smoothing_A0 = 0. #not-treated\n",
        "\n",
        "\n",
        "            if self.is_smoothing:\n",
        "                for m in range(1, self.t_max):\n",
        "                    tmp_Wprev = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope=self.name+'/hypothesis_A1_T{}'.format(m-1))[::2]\n",
        "                    tmp_Wcurr = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope=self.name+'/hypothesis_A1_T{}'.format(m))[::2]\n",
        "                    for l in range(self.num_layers2):\n",
        "                        self.loss_smoothing_A1 += tf.reduce_mean((tmp_Wprev[l] - tmp_Wcurr[l])**2) ## average over each parameter (for scaling)\n",
        "                    \n",
        "                    if self.is_treat:\n",
        "                        tmp_Wprev = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope=self.name+'/hypothesis_A0_T{}'.format(m-1))[::2]\n",
        "                        tmp_Wcurr = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope=self.name+'/hypothesis_A0_T{}'.format(m))[::2]\n",
        "                        for l in range(self.num_layers2):\n",
        "                            self.loss_smoothing_A0 += tf.reduce_mean((tmp_Wprev[l] - tmp_Wcurr[l])**2) ## average over each parameter (for scaling)\n",
        "            \n",
        "            self.loss_smoothing = self.loss_smoothing_A1 + self.loss_smoothing_A0             \n",
        "                    \n",
        "            tmp_w1 = div(self.w[:, :, 0], tf.reduce_sum(self.mask2 * self.a * self.w[:, :, 0], axis=0, keepdims=True) )\n",
        "            tmp_w1 = self.mask2 * self.a * tmp_w1\n",
        "            \n",
        "            if self.is_treat:\n",
        "                tmp_w0 = div(self.w[:, :, 1], tf.reduce_sum(self.mask2 * (1.- self.a) * self.w[:, :, 1], axis=0, keepdims=True) )\n",
        "                tmp_w0 = self.mask2 * (1. - self.a) * tmp_w0\n",
        "                            \n",
        "            ### loss - factual loss\n",
        "            self.loss      = 0\n",
        "            loss_A1        = tf.reduce_sum(\n",
        "                tmp_w1 * self.mask2 * self.a * tf.nn.sigmoid_cross_entropy_with_logits(labels=y_expanded, logits=self.logits_A1)\n",
        "            )\n",
        "            self.loss     += loss_A1\n",
        "            if self.is_treat:\n",
        "                loss_A0        = tf.reduce_sum(\n",
        "                    tmp_w0 * self.mask2 * (1.- self.a) * tf.nn.sigmoid_cross_entropy_with_logits(labels=y_expanded, logits=self.logits_A0)\n",
        "                )            \n",
        "                self.loss     += loss_A0            \n",
        "                   \n",
        "            ### l2-regularization    \n",
        "            self.vars_encoder = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope=self.name+'/encoder')\n",
        "            \n",
        "            if self.reg_scale != 0:\n",
        "                vars_reg          = [w for w in self.vars_encoder if 'weights' in w.name]\n",
        "                regularizer       = slim.layers.l2_regularizer(scale=self.reg_scale, scope=None)\n",
        "                loss_reg          = slim.layers.apply_regularization(regularizer, vars_reg)   \n",
        "            else:\n",
        "                loss_reg          = 0.\n",
        "\n",
        "\n",
        "            self.solver       = tf.compat.v1.train.AdamOptimizer(learning_rate=self.lr_rate).minimize(self.loss)\n",
        "            \n",
        "            self.loss_total   = self.loss + self.beta * self.loss_IPM + self.gamma * self.loss_smoothing + loss_reg\n",
        "            self.solver_total = tf.compat.v1.train.AdamOptimizer(learning_rate=self.lr_rate).minimize(self.loss_total)\n",
        "            \n",
        "            \n",
        "            ### batch-normalization operation\n",
        "            self.extra_update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS) \n",
        "                      \n",
        "                    \n",
        "\n",
        "    def predict_hazard_A1(self, x_):\n",
        "        odd    = tf.exp(self.logits_A1)\n",
        "        hazard = odd / (1. + odd)\n",
        "        return self.sess.run(hazard, feed_dict={self.x:x_, self.k_prob:1.0, self.is_training: False})\n",
        "         \n",
        "    def predict_hazard_A0(self, x_):\n",
        "        odd    = tf.exp(self.logits_A0)\n",
        "        hazard = odd / (1. + odd)\n",
        "        return self.sess.run(hazard, feed_dict={self.x:x_, self.k_prob:1.0, self.is_training: False})\n",
        "    \n",
        "    def predict_survival_A1(self, x_):\n",
        "        hazard         = self.predict_hazard_A1(x_)  \n",
        "        surv           = np.ones_like(hazard)\n",
        "#         surv[:, 1:]    = np.cumprod(1. - hazard, axis=1)[:, :-1]\n",
        "        surv[:, :]    = np.cumprod(1. - hazard, axis=1)\n",
        "        return surv\n",
        "    \n",
        "    def predict_survival_A0(self, x_):\n",
        "        hazard         = self.predict_hazard_A0(x_)  \n",
        "        surv           = np.ones_like(hazard)\n",
        "#         surv[:, 1:]    = np.cumprod(1. - hazard, axis=1)[:, :-1]\n",
        "        surv[:, :]    = np.cumprod(1. - hazard, axis=1)\n",
        "        return surv\n",
        "        \n",
        "        \n",
        "    def train_baseline(self, x_, y_, t_, a_, lr_train_=1e-3, k_prob_=1.0):\n",
        "        return self.sess.run([self.solver, self.extra_update_ops, self.loss],\n",
        "                             feed_dict={self.x:x_, self.y:y_, self.t:t_, self.a:a_, self.w:np.ones([np.shape(x_)[0], self.t_max, 2]),\n",
        "                                        self.lr_rate:lr_train_, \n",
        "                                        self.k_prob:k_prob_,\n",
        "                                        self.is_training: True})\n",
        "\n",
        "    def get_loss_basline(self, x_, y_, t_, a_, k_prob_=1.0):\n",
        "        return self.sess.run(self.loss,\n",
        "                             feed_dict={self.x:x_, self.y:y_, self.t:t_, self.a:a_, self.w:np.ones([np.shape(x_)[0], self.t_max, 2]),\n",
        "                                        self.k_prob:k_prob_,\n",
        "                                        self.is_training: False})\n",
        "    \n",
        "    \n",
        "    def train(self, x_, y_, t_, a_, w_, beta_=1e-3, gamma_=1e-3, lr_train_=1e-3, k_prob_=1.0):\n",
        "        if not self.is_smoothing:\n",
        "            gamma_ = 0.\n",
        "        return self.sess.run([self.solver_total, self.extra_update_ops, self.loss_total, self.loss, self.loss_IPM],\n",
        "                             feed_dict={self.x:x_, self.y:y_, self.t:t_, self.a:a_, self.w:w_,\n",
        "                                        self.beta:beta_, self.gamma:gamma_,\n",
        "                                        self.lr_rate:lr_train_, \n",
        "                                        self.k_prob:k_prob_,\n",
        "                                        self.is_training: True})\n",
        "\n",
        "    def get_loss(self, x_, y_, t_, a_, w_, beta_=1e-3, gamma_=1e-3, k_prob_=1.0):\n",
        "        if not self.is_smoothing:\n",
        "            gamma_ = 0.\n",
        "        return self.sess.run([self.loss_total, self.loss, self.loss_IPM],\n",
        "                             feed_dict={self.x:x_, self.y:y_, self.t:t_, self.a:a_, self.w:w_,\n",
        "                                        self.beta:beta_, self.gamma:gamma_,\n",
        "                                        self.k_prob:k_prob_,\n",
        "                                        self.is_training: False})\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIG-qaok2E5O"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sksurv.metrics import concordance_index_ipcw\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swE7rKwf24uy"
      },
      "outputs": [],
      "source": [
        "ipm_type      = 'wasserstein'\n",
        "\n",
        "weight        = False\n",
        "is_smoothing  = False\n",
        "is_treat      = True\n",
        "\n",
        "is_training   = True#True\n",
        "\n",
        "OUT_ITERATION = 5\n",
        "N_tr = 5000\n",
        "N_te = 5000\n",
        "\n",
        "if not weight:\n",
        "    weight_type = 'noweight'\n",
        "else:\n",
        "    weight_type  = '' \n",
        "\n",
        "\n",
        "if ipm_type == 'no_ipm':\n",
        "    beta       = 0.\n",
        "else:\n",
        "    beta   = 1e-3 #1e-3\n",
        "\n",
        "    \n",
        "if is_smoothing:\n",
        "    gamma  = 1e-3\n",
        "else:\n",
        "    gamma  = 0.\n",
        "\n",
        "\n",
        "lr_rate   = 1e-3\n",
        "mb_size   = 512\n",
        "\n",
        "keep_prob = 0.7\n",
        "\n",
        "seed           = 1234\n",
        "\n",
        "TMAX           = 30\n",
        "eval_times     = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
        "\n",
        "\n",
        "# results_mse_hzrd1 = np.zeros([OUT_ITERATION, TMAX+1])\n",
        "# results_mse_hzrd0 = np.zeros([OUT_ITERATION, TMAX+1])\n",
        "\n",
        "# results_mse_surv1 = np.zeros([OUT_ITERATION, TMAX+1])\n",
        "# results_mse_surv0 = np.zeros([OUT_ITERATION, TMAX+1])\n",
        "\n",
        "# results_hte_hzrd   = np.zeros([OUT_ITERATION, TMAX+1])\n",
        "# results_hte_surv   = np.zeros([OUT_ITERATION, TMAX+1])\n",
        "\n",
        "# results1 = np.zeros([OUT_ITERATION, len(eval_times)])\n",
        "# results2 = np.zeros([OUT_ITERATION, len(eval_times)])\n",
        "# results3 = np.zeros([OUT_ITERATION, len(eval_times)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLPRBZKN44bt"
      },
      "outputs": [],
      "source": [
        "seed         = 1234\n",
        "modelname    = 'SurvITE'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lVg1av06sZL"
      },
      "source": [
        "# Import Observational Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQlqQlf1493T"
      },
      "outputs": [],
      "source": [
        "# download data\n",
        "import requests\n",
        "import io\n",
        "\n",
        "# response = requests.get('https://raw.githubusercontent.com/chl8856/survITE/d7f217fb2bc2406ec11656be49c4fc29156372fb/data/tr_data.npz')\n",
        "# response.raise_for_status()\n",
        "# npz = np.load(io.BytesIO(response.content))\n",
        "# tr_x = npz['x']\n",
        "# tr_a = npz['a']\n",
        "# tr_t = npz['t']\n",
        "# tr_y = npz['y']\n",
        "\n",
        "# response_te = requests.get('https://raw.githubusercontent.com/chl8856/survITE/d7f217fb2bc2406ec11656be49c4fc29156372fb/data/te_data.npz')\n",
        "# response_te.raise_for_status()\n",
        "# npz = np.load(io.BytesIO(response_te.content))\n",
        "# te_x = npz['x']\n",
        "# te_a = npz['a']\n",
        "# te_t = npz['t']\n",
        "# te_y = npz['y']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSL5c4gK47Sy"
      },
      "outputs": [],
      "source": [
        "# npz  = np.load('./data/tr_data.npz')\n",
        "# tr_x = npz['x']\n",
        "# tr_a = npz['a']\n",
        "# tr_t = npz['t']\n",
        "# tr_y = npz['y']\n",
        "\n",
        "# npz  = np.load('./data/te_data.npz')\n",
        "# te_x = npz['x']\n",
        "# te_a = npz['a']\n",
        "# te_t = npz['t']\n",
        "# te_y = npz['y']\n",
        "\n",
        "tr_y_structured = [(tr_y[i], tr_t[i]) for i in range(len(tr_y))]\n",
        "tr_y_structured = np.array(tr_y_structured, dtype=[('status', 'bool'),('time','<f8')])\n",
        "\n",
        "te_y_structured = [(te_y[i], te_t[i]) for i in range(len(te_y))]\n",
        "te_y_structured = np.array(te_y_structured, dtype=[('status', 'bool'),('time','<f8')])\n",
        "\n",
        "TMAX           = 30\n",
        "eval_times     = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
        "\n",
        "\n",
        "results_mse_hzrd1 = np.zeros([1, TMAX+1])\n",
        "results_mse_hzrd0 = np.zeros([1, TMAX+1])\n",
        "\n",
        "results_mse_surv1 = np.zeros([1, TMAX+1])\n",
        "results_mse_surv0 = np.zeros([1, TMAX+1])\n",
        "\n",
        "results_hte_hzrd   = np.zeros([1, TMAX+1])\n",
        "results_hte_surv   = np.zeros([1, TMAX+1])\n",
        "\n",
        "results1 = np.zeros([1, len(eval_times)])\n",
        "results2 = np.zeros([1, len(eval_times)])\n",
        "results3 = np.zeros([1, len(eval_times)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBGqFF5L6zu5"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va2lnbvC6y26",
        "outputId": "24fafd01-70b9-4120-f8c9-d16f59ec0108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ]
        }
      ],
      "source": [
        "num_Event   = 1\n",
        "\n",
        "z_dim       = 100\n",
        "x_dim       = np.shape(tr_x)[1]\n",
        "\n",
        "num_layers1  = 3\n",
        "h_dim1       = 100\n",
        "\n",
        "num_layers2  = 2\n",
        "h_dim2       = 100\n",
        "\n",
        "\n",
        "input_dims = {\n",
        "    'x_dim': x_dim,\n",
        "    'num_Event': num_Event,\n",
        "    't_max': TMAX+1\n",
        "}\n",
        "network_settings = {\n",
        "    'z_dim': z_dim,     \n",
        "\n",
        "    # Phi()\n",
        "    'h_dim1': h_dim1, \n",
        "    'num_layers1': num_layers1, \n",
        "\n",
        "    # Hypothesis()\n",
        "    'h_dim2': h_dim2, \n",
        "    'num_layers2': num_layers2,\n",
        "\n",
        "    'active_fn': tf.nn.elu,\n",
        "    'reg_scale': 0.,\n",
        "    'ipm_term' : ipm_type, \n",
        "    'is_treat' : is_treat,\n",
        "    'is_smoothing': is_smoothing\n",
        "}\n",
        "\n",
        "\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.Session(config=config)\n",
        "\n",
        "model = SurvITE(sess, 'SurvITE', input_dims, network_settings)\n",
        "sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "saver       = tf.compat.v1.train.Saver()\n",
        "\n",
        "savepath = './{}/surviTE/'.format(modelname)\n",
        "\n",
        "if not os.path.exists(savepath):\n",
        "    os.makedirs(savepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgBhMdqh65_H"
      },
      "outputs": [],
      "source": [
        "if not is_treat:\n",
        "    tr_a = np.ones_like(tr_t)\n",
        "    te_a = np.ones_like(te_t)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tr_y = tr_y.reshape([-1,1])\n",
        "tr_t = tr_t.reshape([-1,1])\n",
        "tr_a = tr_a.reshape([-1,1])\n",
        "\n",
        "if is_treat:\n",
        "    tr_w  = np.ones([np.shape(tr_x)[0], TMAX+1, 2])\n",
        "else:\n",
        "    tr_w  = np.ones([np.shape(tr_x)[0], TMAX+1, 1])\n",
        "\n",
        "tr_x_,va_x, tr_y_,va_y, tr_t_,va_t, tr_a_,va_a, tr_w_,va_w = train_test_split(tr_x, tr_y, tr_t, tr_a, tr_w, test_size=0.2, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEX8lh_F6-nY",
        "outputId": "b8aa4b18-517f-4d54-d8f8-6f2351833233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ITR 0100  | TR: loss_T=16.803 loss_S=11.133 loss_IPM=5669.748 | loss_T=13.322 loss_S=12.272 loss_IPM=1049.589\n",
            "model saved...\n",
            "ITR 0200  | TR: loss_T=10.604 loss_S=6.535 loss_IPM=4069.369 | loss_T=7.701 loss_S=6.180 loss_IPM=1520.900\n",
            "model saved...\n",
            "ITR 0300  | TR: loss_T=9.485 loss_S=6.304 loss_IPM=3180.778 | loss_T=7.334 loss_S=6.068 loss_IPM=1265.741\n",
            "model saved...\n",
            "ITR 0400  | TR: loss_T=8.650 loss_S=6.039 loss_IPM=2610.747 | loss_T=6.828 loss_S=5.893 loss_IPM=934.666\n",
            "model saved...\n",
            "ITR 0500  | TR: loss_T=8.130 loss_S=5.927 loss_IPM=2203.163 | loss_T=6.490 loss_S=5.767 loss_IPM=723.283\n",
            "model saved...\n",
            "ITR 0600  | TR: loss_T=7.671 loss_S=5.806 loss_IPM=1865.266 | loss_T=6.285 loss_S=5.706 loss_IPM=579.676\n",
            "model saved...\n",
            "ITR 0700  | TR: loss_T=7.261 loss_S=5.700 loss_IPM=1560.274 | loss_T=6.145 loss_S=5.677 loss_IPM=468.467\n",
            "model saved...\n",
            "ITR 0800  | TR: loss_T=6.930 loss_S=5.631 loss_IPM=1298.259 | loss_T=6.054 loss_S=5.674 loss_IPM=380.043\n",
            "model saved...\n",
            "ITR 0900  | TR: loss_T=6.664 loss_S=5.601 loss_IPM=1063.484 | loss_T=5.910 loss_S=5.604 loss_IPM=305.812\n",
            "model saved...\n",
            "ITR 1000  | TR: loss_T=6.425 loss_S=5.568 loss_IPM=856.242 | loss_T=5.823 loss_S=5.582 loss_IPM=241.435\n",
            "model saved...\n",
            "ITR 1100  | TR: loss_T=6.173 loss_S=5.491 loss_IPM=681.585 | loss_T=5.786 loss_S=5.594 loss_IPM=192.188\n",
            "model saved...\n",
            "ITR 1200  | TR: loss_T=5.961 loss_S=5.421 loss_IPM=539.840 | loss_T=5.729 loss_S=5.580 loss_IPM=149.265\n",
            "model saved...\n",
            "ITR 1300  | TR: loss_T=5.914 loss_S=5.487 loss_IPM=427.706 | loss_T=5.690 loss_S=5.572 loss_IPM=117.438\n",
            "model saved...\n",
            "ITR 1400  | TR: loss_T=5.772 loss_S=5.431 loss_IPM=341.373 | loss_T=5.671 loss_S=5.577 loss_IPM=93.650\n",
            "model saved...\n",
            "ITR 1500  | TR: loss_T=5.670 loss_S=5.390 loss_IPM=280.302 | loss_T=5.602 loss_S=5.526 loss_IPM=76.493\n",
            "model saved...\n",
            "ITR 1600  | TR: loss_T=5.631 loss_S=5.391 loss_IPM=239.222 | loss_T=5.599 loss_S=5.533 loss_IPM=65.556\n",
            "model saved...\n",
            "ITR 1700  | TR: loss_T=5.554 loss_S=5.347 loss_IPM=207.388 | loss_T=5.545 loss_S=5.487 loss_IPM=57.829\n",
            "model saved...\n",
            "ITR 1800  | TR: loss_T=5.508 loss_S=5.322 loss_IPM=185.991 | loss_T=5.552 loss_S=5.500 loss_IPM=52.485\n",
            "ITR 1900  | TR: loss_T=5.506 loss_S=5.339 loss_IPM=167.498 | loss_T=5.567 loss_S=5.519 loss_IPM=47.972\n",
            "ITR 2000  | TR: loss_T=5.439 loss_S=5.284 loss_IPM=155.217 | loss_T=5.554 loss_S=5.509 loss_IPM=45.130\n",
            "ITR 2100  | TR: loss_T=5.372 loss_S=5.228 loss_IPM=144.234 | loss_T=5.557 loss_S=5.514 loss_IPM=42.602\n",
            "ITR 2200  | TR: loss_T=5.422 loss_S=5.286 loss_IPM=135.781 | loss_T=5.536 loss_S=5.496 loss_IPM=40.177\n",
            "model saved...\n",
            "ITR 2300  | TR: loss_T=5.293 loss_S=5.165 loss_IPM=128.192 | loss_T=5.552 loss_S=5.514 loss_IPM=38.359\n",
            "ITR 2400  | TR: loss_T=5.318 loss_S=5.200 loss_IPM=118.513 | loss_T=5.588 loss_S=5.552 loss_IPM=35.805\n",
            "ITR 2500  | TR: loss_T=5.355 loss_S=5.240 loss_IPM=115.753 | loss_T=5.547 loss_S=5.511 loss_IPM=35.157\n",
            "ITR 2600  | TR: loss_T=5.236 loss_S=5.127 loss_IPM=109.155 | loss_T=5.556 loss_S=5.522 loss_IPM=33.736\n",
            "ITR 2700  | TR: loss_T=5.205 loss_S=5.101 loss_IPM=103.961 | loss_T=5.589 loss_S=5.557 loss_IPM=31.828\n",
            "ITR 2800  | TR: loss_T=5.305 loss_S=5.206 loss_IPM=99.611 | loss_T=5.590 loss_S=5.559 loss_IPM=31.073\n",
            "ITR 2900  | TR: loss_T=5.211 loss_S=5.117 loss_IPM=93.772 | loss_T=5.582 loss_S=5.553 loss_IPM=29.295\n",
            "ITR 3000  | TR: loss_T=5.212 loss_S=5.123 loss_IPM=88.209 | loss_T=5.582 loss_S=5.555 loss_IPM=27.828\n",
            "ITR 3100  | TR: loss_T=5.147 loss_S=5.062 loss_IPM=85.124 | loss_T=5.603 loss_S=5.576 loss_IPM=27.262\n",
            "ITR 3200  | TR: loss_T=5.170 loss_S=5.090 loss_IPM=80.177 | loss_T=5.588 loss_S=5.562 loss_IPM=25.599\n",
            "ITR 3300  | TR: loss_T=5.111 loss_S=5.034 loss_IPM=76.357 | loss_T=5.622 loss_S=5.597 loss_IPM=24.630\n",
            "ITR 3400  | TR: loss_T=5.161 loss_S=5.087 loss_IPM=73.815 | loss_T=5.610 loss_S=5.587 loss_IPM=23.578\n",
            "ITR 3500  | TR: loss_T=5.120 loss_S=5.049 loss_IPM=70.623 | loss_T=5.639 loss_S=5.615 loss_IPM=23.339\n",
            "ITR 3600  | TR: loss_T=5.148 loss_S=5.079 loss_IPM=68.293 | loss_T=5.623 loss_S=5.601 loss_IPM=22.568\n",
            "ITR 3700  | TR: loss_T=5.046 loss_S=4.980 loss_IPM=65.890 | loss_T=5.637 loss_S=5.615 loss_IPM=21.715\n",
            "ITR 3800  | TR: loss_T=5.022 loss_S=4.959 loss_IPM=63.629 | loss_T=5.649 loss_S=5.628 loss_IPM=21.159\n",
            "ITR 3900  | TR: loss_T=5.087 loss_S=5.025 loss_IPM=61.911 | loss_T=5.636 loss_S=5.616 loss_IPM=20.654\n",
            "ITR 4000  | TR: loss_T=5.003 loss_S=4.943 loss_IPM=60.265 | loss_T=5.661 loss_S=5.641 loss_IPM=20.290\n",
            "ITR 4100  | TR: loss_T=4.978 loss_S=4.919 loss_IPM=59.240 | loss_T=5.671 loss_S=5.652 loss_IPM=19.758\n",
            "ITR 4200  | TR: loss_T=4.972 loss_S=4.914 loss_IPM=58.158 | loss_T=5.692 loss_S=5.672 loss_IPM=19.447\n"
          ]
        }
      ],
      "source": [
        "iterations = 20000\n",
        "\n",
        "avg_tr_loss_total = 0.\n",
        "avg_tr_loss       = 0.\n",
        "avg_tr_loss_ipm   = 0.\n",
        "\n",
        "avg_va_loss_total = 0.\n",
        "avg_va_loss       = 0.\n",
        "avg_va_loss_ipm   = 0.\n",
        "\n",
        "check_step        = 100\n",
        "\n",
        "min_loss          = 1e+8\n",
        "max_flag          = 20\n",
        "stop_flag         = 0\n",
        "\n",
        "if is_training:\n",
        "    for itr in range(iterations):    \n",
        "        if beta == 0.:\n",
        "            x_mb, y_mb, t_mb, a_mb = f_get_minibatch(mb_size, tr_x_, tr_y_, tr_t_, tr_a_)    \n",
        "            _, _, tmp_tr_loss          = model.train_baseline(x_mb, y_mb, t_mb, a_mb, lr_train_=lr_rate, k_prob_=keep_prob)\n",
        "            avg_tr_loss_total         += tmp_tr_loss/check_step\n",
        "            avg_tr_loss               += tmp_tr_loss/check_step\n",
        "\n",
        "            x_mb, y_mb, t_mb, a_mb = f_get_minibatch(min(mb_size, np.shape(va_x)[0]), va_x, va_y, va_t, va_a)    \n",
        "            tmp_va_loss                = model.get_loss_basline(x_mb, y_mb, t_mb, a_mb, k_prob_=keep_prob)\n",
        "            avg_va_loss_total         += tmp_va_loss/check_step\n",
        "            avg_va_loss               += tmp_va_loss/check_step\n",
        "\n",
        "        else:\n",
        "            x_mb, y_mb, t_mb, a_mb, w_mb = f_get_minibatch(mb_size, tr_x_, tr_y_, tr_t_, tr_a_, tr_w_)\n",
        "            _, _, tmp_tr_loss_total, tmp_tr_loss, tmp_tr_loss_ipm = model.train(x_mb, y_mb, t_mb, a_mb, w_mb, \n",
        "                                                                                beta_=beta, gamma_=gamma, \n",
        "                                                                                lr_train_=lr_rate, k_prob_=keep_prob)\n",
        "            avg_tr_loss_total         += tmp_tr_loss_total/check_step\n",
        "            avg_tr_loss               += tmp_tr_loss/check_step\n",
        "            avg_tr_loss_ipm           += tmp_tr_loss_ipm/check_step\n",
        "\n",
        "            x_mb, y_mb, t_mb, a_mb, w_mb = f_get_minibatch(min(mb_size, np.shape(va_x)[0]), va_x, va_y, va_t, va_a, va_w)    \n",
        "            tmp_va_loss_total, tmp_va_loss, tmp_va_loss_ipm      = model.get_loss(x_mb, y_mb, t_mb, a_mb, w_mb, \n",
        "                                                                                  beta_=beta, gamma_=gamma, \n",
        "                                                                                  k_prob_=1.0)\n",
        "            avg_va_loss_total         += tmp_va_loss_total/check_step\n",
        "            avg_va_loss               += tmp_va_loss/check_step\n",
        "            avg_va_loss_ipm           += tmp_va_loss_ipm/check_step\n",
        "\n",
        "        if (itr + 1)%check_step == 0:\n",
        "            stop_flag += 1\n",
        "\n",
        "            print(\n",
        "                \"ITR {:04d}  | TR: loss_T={:.3f} loss_S={:.3f} loss_IPM={:.3f} | loss_T={:.3f} loss_S={:.3f} loss_IPM={:.3f}\".format(\n",
        "                itr+1, avg_tr_loss_total, avg_tr_loss, avg_tr_loss_ipm, avg_va_loss_total, avg_va_loss, avg_va_loss_ipm)\n",
        "            )\n",
        "\n",
        "            if min_loss > avg_va_loss_total:\n",
        "                min_loss  = avg_va_loss_total\n",
        "                stop_flag = 0\n",
        "\n",
        "                saver.save(sess, savepath + 'model_{}{}'.format(ipm_type,weight_type))\n",
        "                print('model saved...')\n",
        "\n",
        "            else:\n",
        "                if stop_flag >= max_flag:\n",
        "                    break\n",
        "\n",
        "\n",
        "            avg_tr_loss_total = 0.\n",
        "            avg_tr_loss = 0.\n",
        "            avg_tr_loss_ipm = 0.\n",
        "\n",
        "            avg_va_loss_total = 0.\n",
        "            avg_va_loss = 0.\n",
        "            avg_va_loss_ipm = 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23M2sM5u7BS2"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "naEcVvA71XjV",
        "outputId": "9e76c609-5a18-4975-a735-b0c245e7ed9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open SurvITE.zip, SurvITE.zip.zip or SurvITE.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "# call this if restoring data\n",
        "!rm -rf SurvITE\n",
        "!unzip SurvITE.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XgHolDB7AYr"
      },
      "outputs": [],
      "source": [
        "saver.restore(sess, savepath + 'model_{}{}'.format(ipm_type,weight_type))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBhcDWII7Fe2"
      },
      "outputs": [],
      "source": [
        "surv1 = model.predict_survival_A1(te_x)\n",
        "surv0 = model.predict_survival_A0(te_x)\n",
        "\n",
        "hzrd1 = model.predict_hazard_A1(te_x)\n",
        "hzrd0 = model.predict_hazard_A0(te_x)\n",
        "\n",
        "hzrd = np.zeros_like(hzrd1)\n",
        "if is_treat:\n",
        "    hzrd[te_a == 0, :] = hzrd0[te_a == 0, :]\n",
        "hzrd[te_a == 1, :] = hzrd1[te_a == 1, :]\n",
        "\n",
        "surv = np.zeros_like(surv1)\n",
        "if is_treat:\n",
        "    surv[te_a == 0, :] = surv0[te_a == 0, :]\n",
        "surv[te_a == 1, :] = surv1[te_a == 1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8P6W4ua3CD_"
      },
      "outputs": [],
      "source": [
        "tr_data = np.load(\"S_1_train_new.npz\")\n",
        "te_data = np.load(\"S_1_test_new.npz\")\n",
        "\n",
        "te_hazs = te_data['haz']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def survival(haz):\n",
        "  surv = []\n",
        "  for patient in haz:\n",
        "    surv_patient = np.cumprod(1-patient)\n",
        "    surv.append(surv_patient)\n",
        "  \n",
        "  return np.array(surv)\n",
        "\n",
        "def RMSE(surv_hat, surv):\n",
        "  rmse = []\n",
        "  \n",
        "  for time_point in range(len(surv[0])):\n",
        "    diff = 0\n",
        "    for patient in range(len(surv_hat)):\n",
        "      diff += (surv[patient, time_point] - surv_hat[patient, time_point])**2\n",
        "    diff = diff / len(surv_hat)\n",
        "    rmse.append(np.sqrt(diff))\n",
        "\n",
        "  return rmse\n",
        "\n",
        "rmse_data = RMSE(surv0, survival(te_hazs))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(np.arange(2, 21), rmse_data[2:21], '-o')\n",
        "ax.set_title(\"S^0(t|x)\")\n",
        "ax.set_xlabel('Time')\n",
        "ax.set_ylabel('RMSE')\n",
        "ax.grid()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "gPlUAFXZzPOv",
        "outputId": "56c223c7-5f75-4842-e46d-38de9279a3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABaYUlEQVR4nO3deVxU9f4/8NcMDIwoi4JsCgJuiCgoAmGLZSiWuXTNa15XMv1pUhr3eouuSdwWtMz0W161umhmpnlzLSWJxDJRFNwQNReUlE1EAUFgmDm/P4jJkQEBhzkznNfz8eihc+YzZ95vh+XVOZ9zPjJBEAQQERERSYhc7AKIiIiIjI0BiIiIiCSHAYiIiIgkhwGIiIiIJIcBiIiIiCSHAYiIiIgkhwGIiIiIJIcBiIiIiCSHAYiIiIgkhwGIiCTrpZdewrBhw5o09vLly5DJZEhJSWn2+2RlZcHS0hKZmZnNfi0RtQ4GICIyqlOnTuG5555Dt27doFQq0aVLFwwbNgwff/yx3vHV1dUYOnQoZDIZxowZA7Va3ej+d+7ciYEDB0KpVMLT0xOxsbGoqampNy47Oxuff/453njjDe223NxcvPXWWzh+/PgD9XgvPz8/jBw5EosWLTLofomo5RiAiMhoDh48iEGDBuHEiROYOXMmPvnkE7z44ouQy+VYsWJFvfGCICAyMhL79u3DyJEjsXPnTrzyyisN7n/Pnj0YO3YsHBwc8PHHH2Ps2LF455138PLLL9cbu2LFCnh7e+OJJ57QbsvNzUVcXJzBAxAAzJ49G9u2bcPFixcNvm8iaj5LsQsgIul49913YW9vjyNHjsDBwUHnucLCwnrjY2Ji8PXXX2PlypV46aWX8M477+DNN9+Ep6cnXnvttXrj//GPf6B///7Yu3cvLC1rf7zZ2dnhvffew7x58+Dr6wsAUKlU+OqrrzB79mzDN9mA8PBwdOzYEV988QX+/e9/G+19iUg/HgEiIqO5ePEi+vbtWy/8AICzs7PO4//85z94//338Z///AcvvfQSAGDhwoV45513tMHobllZWcjKysKsWbO04QeonecjCAL+97//abcdOHAARUVFCA8P125LSUlBcHAwACAyMhIymQwymQzr1q1rsJ/Y2FjI5XIkJyfrbJ81axasrKxw4sQJ7TaFQoHHH38cO3bsaHB/RGQ8DEBEZDTdunVDenr6fScD79y5E/PmzcPq1avrHaX517/+hXfffRfTp0/Hvn37tNuPHTsGABg0aJDOeHd3d3Tt2lX7PFB7Kk4mk2HAgAHabX369NEemZk1axa+/PJLfPnll3jssccarHPhwoUIDAzEjBkzUFZWBgD44Ycf8Nlnn2HRokUICAjQGR8UFITMzEyUlpY22j8RtT4GICIymn/84x+oqKhAYGAgBg8ejNdeew179+6FSqXSGTd69GioVCrMmjVL735iYmJQVVWlM38nLy8PAODm5lZvvJubG3Jzc7WPz549i06dOsHOzk67zcXFBU899RQAICwsDJMnT8bkyZPh4+PTYD8KhQLr169HXl4eoqOjcevWLcyYMQODBg3C66+/Xm+8j48PNBoNzp492+A+icg4GICIyGiGDRuG1NRUjB49GidOnMD777+PiIgIdOnSBTt37nygfd+5cwcAYG1tXe85pVKpfR4Abty4gY4dOz7Q+9Xx9/dHXFwcPv/8c0RERKCoqAhffPGFzmm4OnXvWVRUZJD3JqKWYwAiIqMKDg7G1q1bcfPmTaSlpSEmJgZlZWV47rnnkJWV1eL9tmvXDgBQVVVV77nKykrt83UEQWjxe91rwYIFCAgIQFpaGmJjY+Hn56d3XN17ymQyg703EbUMAxARicLKygrBwcF47733sGrVKqhUKmzZsqXF+6s79VV3KuxueXl5cHd31z52dHTEzZs3W/xe97p06RLOnz8PoPY+Rw2pe08nJyeDvTcRtQwDEBGJrm7isr7w0lSBgYEAgKNHj+psz83NxdWrV7XPA4Cvry9u3ryJkpISnbEtOTKj0Wgwffp02NnZ4Y033sDXX3+NrVu36h2bnZ0NuVyOXr16Nft9iMiwGICIyGj27dun99TT7t27AQC9e/du8b779u0LX19ffPrppzp3i161ahVkMhmee+457bawsDAIgoD09HSdfbRv3x4AcOvWrSa/77Jly3Dw4EF8+umnePvttzF48GDMmTNH7zyf9PR09O3bF/b29s3sjogMjTdCJCKjefnll1FRUYFnn30Wvr6+qK6uxsGDB7F582Z4eXkhMjLygfb/wQcfYPTo0Rg+fDief/55ZGZmau823adPH+24Rx55BI6Ojvjxxx8xdOhQ7fbu3bvDwcEBq1evhq2tLdq3b4/Q0FB4e3vrfb8zZ87gzTffxPTp0zFq1CgAwLp16xAYGIiXXnoJ33zzjXasSqXC/v37tfc0IiKRCURERrJnzx7hhRdeEHx9fYUOHToIVlZWQo8ePYSXX35ZKCgoMMh7bNu2TQgMDBSsra2Frl27CgsXLhSqq6vrjXvllVeEHj161Nu+Y8cOwc/PT7C0tBQACGvXrhUEQRCys7MFAMK+ffsEQRCEmpoaITg4WOjatatw69YtnX2sWLFCACBs3rxZp3cAwvnz5w3SJxE9GJkgGPBSCCIiM3Hp0iX4+vpiz549ePLJJ+87/vLly/D29sa+ffvw+OOPN/v9xo4dC5lMhm3btrWgWiIyNJ4CIyJJ8vHxwYwZM7B48eImBaAHcebMGXz33XetssgqEbUMAxARSdaqVauM8j59+vRBTU2NUd6LiJqGV4ERERGR5HAOEBEREUkOjwARERGR5DAAERERkeRwErQeGo0Gubm5sLW15aKFREREZkIQBJSVlcHd3R1yeePHeBiA9MjNzYWHh4fYZRAREVEL/P777+jatWujYxiA9LC1tQVQ+w9oZ2cnai0qlQp79+7F8OHDoVAoRK3F2KTau1T7Bti7FHuXat8Ae2+N3ktLS+Hh4aH9Pd4YBiA96k572dnZmUQAsrGxgZ2dnSS/QaTYu1T7Bti7FHuXat8Ae2/N3psyfYWToImIiEhyGICIiIhIchiAiIiISHJED0ArV66El5cXlEolQkNDkZaW1uDY06dPY9y4cfDy8oJMJsPy5cv1jrt27RomT54MR0dHtGvXDv369cPRo0dbqQMiIiIyN6IGoM2bNyM6OhqxsbHIyMhAQEAAIiIiUFhYqHd8RUUFfHx8sHjxYri6uuodc/PmTTz88MNQKBTYs2cPsrKy8OGHH6Jjx46t2QoRERGZEVGvAlu2bBlmzpyJyMhIAMDq1avx/fffIyEhAa+//nq98cHBwQgODgYAvc8DwJIlS+Dh4YG1a9dqt3l7e7dC9URERGSuRAtA1dXVSE9PR0xMjHabXC5HeHg4UlNTW7zfnTt3IiIiAuPHj8f+/fvRpUsXvPTSS5g5c2aDr6mqqkJVVZX2cWlpKYDay/RUKlWLazGEuvcXuw4xSLV3qfYNsPe7/5QKqfYNsPe7/zT0fptCtABUVFQEtVoNFxcXne0uLi44e/Zsi/d76dIlrFq1CtHR0XjjjTdw5MgRvPLKK7CyssK0adP0viY+Ph5xcXH1tu/duxc2NjYtrsWQkpKSxC5BNFLtXap9A+xdiqTaN8DeDamioqLJY9vcjRA1Gg0GDRqE9957DwAwYMAAZGZmYvXq1Q0GoJiYGERHR2sf191Jcvjw4SZxI8SkpCQMGzZMkjfKkmLvUu0bYO9S7F2qfQPsvTV6rzuD0xSiBSAnJydYWFigoKBAZ3tBQUGDE5ybws3NDX5+fjrb+vTpg2+//bbB11hbW8Pa2rredoVCYTJflKZUi7FJtXep9g2wdyn2LtW+Aen1rtYIyMguRnqRDI5XyxDWwxkWcsMsPN6cf0fRrgKzsrJCUFAQkpOTtds0Gg2Sk5MRFhbW4v0+/PDDOHfunM623377Dd26dWvxPomIiOjBJWbm4ZElP2FywlGsP2+ByQlH8ciSn5CYmWf0WkS9DD46OhqfffYZvvjiC5w5cwZz5sxBeXm59qqwqVOn6kySrq6uxvHjx3H8+HFUV1fj2rVrOH78OC5cuKAd8+qrr+LQoUN47733cOHCBWzcuBGffvop5s6da/T+iIiIqFZiZh7mbMhAXkmlzvb8kkrM2ZBh9BAk6hygCRMm4Pr161i0aBHy8/MRGBiIxMRE7cTonJwcyOV/ZrTc3FwMGDBA+3jp0qVYunQphgwZgpSUFAC1l8pv27YNMTEx+Pe//w1vb28sX74ckyZNMmpvREREVEutERC3KwuCnucEADIAcbuyMMzP1WCnw+5H9EnQUVFRiIqK0vtcXaip4+XlBUHQ98+n65lnnsEzzzxjiPKIiIjoAaVlF9c78nM3AUBeSSXSsosR1t3RKDWJvhQGERERtV2/FZRhVcqF+w8EUFjWcEgyNNGPABEREVHbcqdaje9P5eHrtBykX7nZ5Nc52ypbsSpdDEBERERkEGfySrEpLQdbj11DWWUNAMBSLsOTvs5Iu3wTtyqq9c4DkgFwtVcixLuT0WplACIiIqIWq6iuwXcn8rAxLQfHf7+l3e7ZyQYTgj0wPqgrnO2U2qvAZIBOCKqb8hw7ys9oE6ABBiAiIiJqgdO5Jfg6LQc7juWirOrPoz0RfV0xMcQTg7s7Qn5XoBnh74ZVkwcibleWzoRoV3slYkf5YYS/m1HrZwAiIiIiALWXq6dlF6OwrBLOtrWnpO4+KlNeVYNdJ3LxdVoOTlwt0W73crTB8yGeGDewKzrb1l9Zoc4IfzcM83NF6oVC7P3lMIY/GmrQO0E3BwMQERERITEzr97RGbc/js50cbDBxrQc7Dx+DeXVagCAwqL2aM/fQjzxkI/u0Z7GWMhlCPXuhBtnBITeE7CMiQGIiIhI4urm59w7QTmvpBKzN2TobPNxao+JIZ74y8AucOzQ8NEeU8cAREREJGGN3aX5bqMD3PC30G4I9e4EmUycozaGxABEREQkYfe7S3OdiSHd8JCPce7SbAwMQERERBJUo9Zg/2/XsSL5tyaNN+Zdmo2BAYiIiEhCLhTexpb037E14xqul1U1+XXGvEuzMTAAERERtXFllSp8fzIP3xz9HRk5t7TbHdtbYUygO3aeyMWN26Zzl2ZjYAAiIiJqgwRBwOHsYnxz9HfsOZWPO6ray9ct5DI80bszngvywFBfZ1hZyhHi3cmk7tJsDAxAREREZuB+Nymsk3vrDr5Nv4ot6VeRU1yh3d69c3v8dZAHnh3Ypd7pLFO7S7MxMAARERGZuMZuUjjC3w2VKjWSsgrwzdHfceBCEYQ/DuN0sLbEqAA3PBfkgYGeDo1evl53l+amhKy2gAGIiIjIhDV0k8L8P25SOKRXZxz//RZK7qi0zz3k0wl/HeSBEf6usLFq+q96C7kMYd3bzqXujWEAIiIiMlGN3aSwbtv+364DANztlXguqCueC/KAp6ON0Wo0VwxAREREJqqpNyl842lfzHjEp82ermoNcrELICIiIv2u3Chv0jgXOyXDTzPxCBAREZGJOZNXivWpV/Bt+tUmjW9rNyk0BgYgIiIiE1Bdo0Hi6Xx8mXoZRy7f1G63lMtQo9G/VGlbvUmhMTAAERERiSi/tBJb0i/h6yO/a5emsJTLENHXFVPCuuFmeTVe+ioDgHRuUmgMDEBERERGJggCDl0qRsI5OaIP/wL1H0d4nG2tMTHEE38L9YSL3Z+ntaR2k0JjYAAiIiIykttVNdiacRVfpl7B+cLbqL0WSUCIdydMDeuGiL6uUFjUvz5JajcpNAYGICIiogfQlCUqzheUYX3qFWzNuIry6to1uWysLDCgowoxzz0Mf4/7z+GR0k0KjYEBiIiIqIUaW6LiyT4uSMoqwPrUyzh0qVj7fPfO7THloW4Y3d8Fv/yUhN6utmKULnkMQERERC3Q0BIVeX8sUWHfzhIld2oAAHIZMMzPBVPDvDC4uyNkMhlUKlX9nZLRMAARERE1U2NLVNQpuVMDx/YKTAzphr+FesLdoZ3R6qP7YwAiIiJqpqYuUfHRhEA81svZCBVRc3EpDCIiomYqLLt/+AGAmxU8zWWqGICIiIia6c4fV3LdD5eoMF08BUZERNRElSo1ViSfx5r9FxsdxyUqTB8DEBERURMcvFiEN7aewuUbFQCAAR4OOPb7LcjAJSrMEQMQERFRI0oqVHh3dxa+OVq7MruLnTX+PcYfEX1d9d4HiEtUmAcGICIiIj0EQcD3p/Lw1s4sFN2uXaR08kOe+OcIX9gpFQC4RIU5YwAiIiK6R+6tO1i0IxM/nikEUHv35sXj+iPYq/6cHi5RYZ4YgIiIiP6g0QjYcPgKluw5i/JqNRQWMsx5vAfmPtEd1pYWYpdHBsQAREREBOC3gjK8/u1JZOTcAgAM9HTA4nH90cuFa3W1RQxAREQkaVU1aqzcdxGrUi5ApRbQwdoS/xzRG5NDu0HOuTxtFgMQERFJ1pHLxXj925O4eL0cABDexxlvj/WHmz3X7WrrGICIiKjNUmsEvVdolVaqsGTPWXx1OAcA4NTBGnGj++Lpfq6QyXjURwpMYimMlStXwsvLC0qlEqGhoUhLS2tw7OnTpzFu3Dh4eXlBJpNh+fLlje578eLFkMlkmD9/vmGLJiIik5aYmYdHlvyEiZ8dwrxNxzHxs0N4ZMlPiN9zBsOW7deGnwmDPJAcPQQj+7sx/EiI6AFo8+bNiI6ORmxsLDIyMhAQEICIiAgUFhbqHV9RUQEfHx8sXrwYrq6uje77yJEjWLNmDfr3798apRMRkYlKzMzDnA0Z9VZszyupxJr9l1BQWgVvp/b4euZDWPJcf9jbKESqlMQiegBatmwZZs6cicjISPj5+WH16tWwsbFBQkKC3vHBwcH44IMP8Pzzz8Pa2rrB/d6+fRuTJk3CZ599ho4dO7ZW+UREZGLUGgFxu7J0lqe4VwdrC3z38iO8f4+EiToHqLq6Gunp6YiJidFuk8vlCA8PR2pq6gPte+7cuRg5ciTCw8PxzjvvNDq2qqoKVVVV2selpaUAAJVKBZVK9UB1PKi69xe7DjFItXep9g2w97v/lIrW6PtwdnG9Iz/3ul2lxrErNxAq4mKlUv3MgdbrvTn7EzUAFRUVQa1Ww8XFRWe7i4sLzp492+L9btq0CRkZGThy5EiTxsfHxyMuLq7e9r1798LGxqbFdRhSUlKS2CWIRqq9S7VvgL1LkSH7PnpdBuD+Ny3c+8th3DjT2HEi45DqZw4YvveKioomj21zV4H9/vvvmDdvHpKSkqBUKpv0mpiYGERHR2sfl5aWwsPDA8OHD4ednV1rldokKpUKSUlJGDZsGBQKaZ2jlmrvUu0bYO9S7N2QfQuCgB/PXMf+s+cA3Lnv+OGPhop+BEiKnznQer3XncFpClEDkJOTEywsLFBQUKCzvaCg4L4TnBuSnp6OwsJCDBw4ULtNrVbj559/xieffIKqqipYWOj+n4G1tbXe+UQKhcJkvihNqRZjk2rvUu0bYO9S7P1B+hYEAXuzCrDix/PIyqv9BSgDGpwDJEPtiu1hPZxNYtFSqX7mgOF7b86+RA1AVlZWCAoKQnJyMsaOHQsA0Gg0SE5ORlRUVIv2+eSTT+LUqVM62yIjI+Hr64vXXnutXvghIiLzpC/4tLeywPSHveDt2B4L/neydtxdr6mLO7Gj/Ewi/JB4RD8FFh0djWnTpmHQoEEICQnB8uXLUV5ejsjISADA1KlT0aVLF8THxwOonTidlZWl/fu1a9dw/PhxdOjQAT169ICtrS38/f113qN9+/ZwdHSst52IiMxPY8HnxUd80LG9FQCgg9IScbuydCZEu9orETvKDyP83USpnUyH6AFowoQJuH79OhYtWoT8/HwEBgYiMTFROzE6JycHcvmfV+vn5uZiwIAB2sdLly7F0qVLMWTIEKSkpBi7fCIiMpKmBp86I/zdMMzPVe+doIlED0AAEBUV1eApr3tDjZeXFwShebP2GYyIiMxXc4PP3SzkMt7rh/QyiQBERETSo9YIOJxdjPQiGRyzi+tNSm4o+EQ+7I0Zj3g3GnyI7ocBiIiIjC4xM++u+TkWWH/+KNz+mJ8T0deVwYdaHQMQEREZVd06XfdOZsgvqcTsDRno6tAOV2/V3seHwYdaCwMQEREZTWPrdNVtu3rrDmwUcrzwiA+DD7UaBiAiIjKatCas0wUAK54fgGF9W3ZDXKKmEH01eCIiko7CsvuHHwCoUKlbuRKSOgYgIiIyGmfbpq3R2NRxRC3FU2BERGQU5VU12HXyWqNj6tbpChFxkVKSBgYgIiJqdQcvFuGf/zuJqzf/XKX93gVLuU4XGRMDEBERtZryqhos3nMWXx66AgDo4tAOHzzXH6WVKq7TRaJiACIiolaRevEG/vntCfxeXHvUZ1KoJ2Ke7oMO1rW/eob5uSL1QiH2/nIYwx8NrXcnaKLWxABEREQGVVFdgyV7zuKL1D+P+iwZ1x+P9HTSGWchlyHUuxNunBEQykVKycgYgIiIyGAOXbqBf/7vJHKKKwAAE0M88cbTvrBVKkSujEgXAxARET2wiuoavJ94DusOXgYAuNsrseS5/ni0Z2dxCyNqAAMQERE9kMOXbuCf357ElRt1R3088MbTfXjUh0waAxAREbVI3VGfL1IvQxAAN3slFo/rjyG9eNSHTB8DEBERNVtadjEW/O+E9qjPhEEe+NczfWDHoz5kJhiAiIioHrVGQFp2MQrLKuFsW3tnZgu5DHeq1fjgh3NYezBbe9Qn/i/98HhvZ7FLJmoWBiAiItKRmJlX7yaFbvZKTAr1xLcZ15BdVA4A+Ougrlj4jB+P+pBZYgAiIiKtxMw8zNmQobNEBQDklVRi6d7fAACudkrEj+uHJ3jUh8wYAxAREQGoPe0VtyurXvi5WzuFBXbPexSd2lsZrS6i1iAXuwAiIjINadnFOqe99LmjUuNcfpmRKiJqPQxAREQEACgsazz8NHcckSljACIiIhSWVWJPZl6TxjrbKlu5GqLWxzlAREQSVnS7CqtTLmLD4SuoVGkaHSsD4Gpfe0k8kbljACIikqDi8mqs+fki1h+8gjsqNQBggKcDHu3phI+TLwCAzmTounXaY0f5cdV2ahMYgIiIJORWRTU+++US1v16GeXVtcEnoKs95g/rhcd7dYZMJoOfm129+wC52isRO8oPI/zdxCqdyKAYgIiIJKDkjgr/PZCNhAPZuF1VAwDo626H6GG9MNTXGTLZn0d1Rvi7YZifq947QRO1FQxARERtWFmlCmt/vYzPfrmEssra4OPraotXh/XCcD8XneBzNwu5DGHdHY1ZKpFRMQAREbVBt6tq8MXBy/j050souaMCAPRy6YBXw3shoq8r5DyaQxLHAEREZGYaWqgUACqqa7A+9Qo+/fkSisurAQDdO7fH/PBeGNnPjcGH6A8MQEREZqShhUpff8oX18uqsHr/RRTdrg0+3k7tMe/JnhgV4M75O0T3YAAiIjITjS1UOm/Tce1jz042mPdkT4wJdIelBe93S6QPAxARkRloykKlFjLg3Wf7YVxQVygYfIgaxe8QIiIz0JSFStUC0M2xPcMPURPwu4SIyAxwoVIiw2IAIiIycYIg4GLh7SaN5UKlRE3DOUBERCbs2q07eHN7Jn46W9joOC5UStQ8PAJERGSC1BoBCQeyMWzZfvx0thAKCxme6e8GGf5cmLQOFyolaj4eASIiMjFn8krx+tZTOPH7LQDAoG4dsXhcP/RwtsUz/evfB4gLlRI1HwMQEZGJqFYDHyadx+cHLqNGI8DW2hKvP+2LicGe2js4c6FSIsNgACIiMgGpl25gyUkLFFVmAwBG9HVF3Ji+cLGrP6mZC5USPTiTmAO0cuVKeHl5QalUIjQ0FGlpaQ2OPX36NMaNGwcvLy/IZDIsX7683pj4+HgEBwfD1tYWzs7OGDt2LM6dO9eKHRARtczN8mos2HICU9emo6hSBhdba6yZEoTVU4L0hh8iMgzRA9DmzZsRHR2N2NhYZGRkICAgABERESgs1H/FQ0VFBXx8fLB48WK4urrqHbN//37MnTsXhw4dQlJSElQqFYYPH47y8vLWbIWIqMkEQcCO49cQvmw/tqRfhUwGPOKiwZ5XBiOir/6fbURkOKKfAlu2bBlmzpyJyMhIAMDq1avx/fffIyEhAa+//nq98cHBwQgODgYAvc8DQGJios7jdevWwdnZGenp6XjssccM3AERUfNcvVmBhdszkXLuOgCgp3MHvDPGD/mZB2GrVIhcHZE0iBqAqqurkZ6ejpiYGO02uVyO8PBwpKamGux9SkpKAACdOvH+GEQkHrVGwNpfs/Hh3t9wR6WGlYUcUUN7YPaQ7pAJauzOFLtCIukQNQAVFRVBrVbDxcVFZ7uLiwvOnj1rkPfQaDSYP38+Hn74Yfj7++sdU1VVhaqqKu3j0tJSAIBKpYJKpTJIHS1V9/5i1yEGqfYu1b6BttG7WiPg6JWbKCyrgrOtNQZ16wgLuQxZeaVYuCMLp67V/nwZ1M0B74zpi+6d2wOCuk303hJS7Rtg73f/aej9NoXop8Ba29y5c5GZmYkDBw40OCY+Ph5xcXH1tu/duxc2NjatWV6TJSUliV2CaKTau1T7Bsy39xM3ZNh6WY5b1X9ekm5vJcCzvYDTN2XQQIZ2FgJGd9PgIecinDuyH/denmGuvT8oqfYNsHdDqqioaPJYUQOQk5MTLCwsUFBQoLO9oKCgwQnOzREVFYXvvvsOP//8M7p27drguJiYGERHR2sfl5aWwsPDA8OHD4ednd0D1/EgVCoVkpKSMGzYMCgU0pobINXepdo3YN69/3C6AGtTT0C4Z3tJtQyn/ghEI/q64M2RvnC2ta73enPu/UFItW+AvbdG73VncJpC1ABkZWWFoKAgJCcnY+zYsQBqT1klJycjKiqqxfsVBAEvv/wytm3bhpSUFHh7ezc63traGtbW9X8gKRQKk/miNKVajE2qvUutb7VGQEZ2MdKLZHC8WoawHs5mc3M/tUbAu3vO1Qs/d+too8DKSUH37Ulqn3sdqfYNsHdD9t6cfYl+Ciw6OhrTpk3DoEGDEBISguXLl6O8vFx7VdjUqVPRpUsXxMfHA6idOJ2VlaX9+7Vr13D8+HF06NABPXr0AFB72mvjxo3YsWMHbG1tkZ+fDwCwt7dHu3btROiSiBqTmHn38g4WWH/+KNzMaHmHtOxinaUp9LlZoUJadjFvYEhkIkQPQBMmTMD169exaNEi5OfnIzAwEImJidqJ0Tk5OZDL/7xdUW5uLgYMGKB9vHTpUixduhRDhgxBSkoKAGDVqlUAgMcff1znvdauXYvp06e3aj9E1DyJmXmYsyGj3tGT/JJKzNmQgVWTB5p8CDp17VaTxhWWNR6SiMh4RA9AQO1cnYZOedWFmjpeXl4QhMYONOO+zxORaVBrBMTtytJ76khA7SrncbuyMMzP1SRPhx3LuYlVKRexN6vg/oMBONvyzs5EpsIkAhARSdP9Th0JAPJKKk3q1JEgCPj5fBFWpVzAoUvF2u3WlnJU1Wj0vkaG2hXbQ7x5LzIiU8EARESiaeopoR3Hr8HPzQ72NuJNFK1Ra7AnMx+rUi4iK6/2ShNLuQxjB3TB7CE+uFB4G3M2ZACAzhGtuuNWsaP8TPIoFpFUMQARkWiaekpo05Hf8W3GVTzWszNGB7ojvI8L2lsb58dXpUqN/6VfxWe/XMKVG7X3GLGxssDEEE/MeMQb7g61F1b0cLbFqskD75rMXcvVjCZzE0kJAxARicbZ1hpyGaBpZNqerdIS7vZKnCu4jeSzhUg+W4h2Cgs82ccZowPcMaR3Z1hbWhi8ttJKFTYcuoKEA5dRdLv2TvEdbRSYPtgbU8O6oWN7q3qvGeHvhmF+rkjLLkZhWSWcbWtPe/HID5HpYQAiIlFcLirHpM8PNxh+6iLDB8/1xwh/N5wvKMPOE7nYeSIXV25U4LuTefjuZB5slZYY0dcVowPdEebjCEsLuf4dNlFhaSUSfr2Mrw5dQVlVDQCgi0M7vPioNyYEe8DGqvEfmxZymcnMVyKihjEAEZHRXS4qx/OfHkJ+aSV6OnfAi4/6YPmPvzV66qiniy3+Prw3oof1wqlrJdh5PBffncxDfmkltqRfxZb0q3DqYIWn+7lhdIA7Bnp2hPyeIy9qjdDg0ZnLReVY8/MlfJt+FdXq2snMvVw6YPaQ7hgV4A7FAwYrIjItDEBEZFT3hp+NMx9CZ1trPBfUFakXCrH3l8MY/mhog3eClslk6N/VAf27OuCNp/sg7XIxdp3Ixe5TeSi6XY31qVewPvUKuji0wzMBtWHIz80OP5zOrzc/x81eicjBXjhxrQR7TuVpj0YN9HTAS4/3wFBf53ohiojaBgYgIjKahsIPUHvqKNS7E26cERDaxHkzcrkMD/k44iEfR7w1ui8OXCjCruO5+OF0Pq7duoM1+y9hzf5LcLGzRkFpVb3X55VU4r09Z7WPn+jdGXMe74Fgr46QyRh8iNoyBiAiMorGwo8hKCzkeKK3M57o7YxKlRo/nS3ErhO5+PFMgd7wc7d2Cjm2zB4M/y72BquHiEwbT2oTUatr7fBzL6XCAk/3c8OqyUFYMznovuPvqDQoq6xptXqIyPQwABFRqzJ2+LlX3ZVc98N1uoikhQGIiFqN2OEHaPrNFrlOF5G0MAARUaswhfADACHeneBmr0RDU5plqL0ajOt0EUkLAxARGZyphB+g9uqy2FF+AFAvBHGdLiLpYgAiIoMypfBTZ4S/G1ZNHghXe93TXK72SqyaPJDrdBFJEC+DJyKDMcXwU4frdBHR3RiAiMggTDn81OE6XURUh6fAiOiBmUP4ISK6GwMQET0Qhh8iMkcMQETUYgw/RGSuGICIqEUYfojInHESNBHdl1oj6Fw95WxrjUmfH2b4ISKzxQBERI1KzMxD3K4s5JX8uVaWXAZoBDD8EJHZYgAiogYlZuZhzoYMCPds1/yx4cVHfRh+iMgscQ4QEeml1giI25VVL/zcbfmPv0GtaWwEEZFpYgAiIr3Ssot1Tnvpk1dSibTsYiNVRERkOAxARKRXYVnj4ae544iITAkDEBHp5WyrvP+gZowjIjIlnARNRHrdqqhu9HkZaldTD/HuZJyCiIgMiEeAiKieb9OvIurrY9rH966XXvc4dpQfV1MnIrPEAEREOhIOZOPvW05ArRHwXFBXrPzbALja657mcrVXYtXkgRjh7yZSlURED4anwIgIACAIApb/eB4rks8DAGY84o1/Pd0HcrkMI/zddO4EHeLdiUd+iMisMQARETQaAf/+LgvrDl4GAPxjeC/MfaIHZLLakGMhlyGsu6OIFRIRGRYDEJHEqdQavPa/k9h67BoA4N9j+mJqmJe4RRERtTIGICIJq1SpEbXxGH48UwALuQwfjg/A2AFdxC6LiKjVMQARSVRZpQoz1x/FoUvFsLaU4z+TBuLJPi5il0VEZBQMQEQSVFxejelr03Dyagk6WFvi82mD8JAP5/gQkXQwABFJTF7JHUz+/DAuXi9Hp/ZWWP9CCPy72ItdFhGRUTEAEUlIdlE5Jn9+GNdu3YG7vRLrZ4Sih3MHscsiIjI6BiAiicjKLcXUhMMoul0NH6f2+PLFUHRxaCd2WUREomAAIpKAo5eLEbnuCMoqa+DnZof1M0Lg1MFa7LKIiETDAETUxqWcK8TsDemoVGkQ7NUR/50eDDulQuyyiIhExQBE1IbtOpGL6G+OQ6UW8Hjvzlg1KQjtrCzELouISHQmsRjqypUr4eXlBaVSidDQUKSlpTU49vTp0xg3bhy8vLwgk8mwfPnyB94nUVu08XAOXtl0DCq1gFEB7vh0yiCGHyKiP4gegDZv3ozo6GjExsYiIyMDAQEBiIiIQGFhod7xFRUV8PHxweLFi+Hq6mqQfRKZM7VGQOrFG9hx/BpSL96AWiNgVcpFvLHtFAQBmBTqieUTAmFlKfq3OxGRyRD9FNiyZcswc+ZMREZGAgBWr16N77//HgkJCXj99dfrjQ8ODkZwcDAA6H2+JfskMleJmXmI25WFvJJK7bb2VhYor1YDAOY+0R3/GN5bu6gpERHValYAKiwshLOzc4PP19TUICMjAyEhIU3aX3V1NdLT0xETE6PdJpfLER4ejtTU1OaU9kD7rKqqQlVVlfZxaWkpAEClUkGlUrWoDkOpe3+x6xCDVHtvat8/nC7Ay5tOQLhne134GRvohvlDu6OmpqY1ymwVUv3MAen2LtW+AfZ+95+G3m9TNCsAubm5IS8vTxuC+vXrh927d8PDwwMAcOPGDYSFhUGtVjdpf0VFRVCr1XBx0V1/yMXFBWfPnm1OaQ+0z/j4eMTFxdXbvnfvXtjY2LSoDkNLSkoSuwTRSLX3xvrWCEBchsUf4Uff0R0BKVm5+E75O+RmePBHqp85IN3epdo3wN4NqaKiosljmxWABEH3/zUvX75cL23dO8YcxMTEIDo6Wvu4tLQUHh4eGD58OOzs7ESsrDbNJiUlYdiwYVAopHXpslR7b0rfh7OLcevQ0Ub2IsOtaqCz30MI9e7UOoW2Aql+5oB0e5dq3wB7b43e687gNIXB5wA1Z66Bk5MTLCwsUFBQoLO9oKCgwQnOrbFPa2trWFvXvymcQqEwmS9KU6rF2KTae2N936ho2mmtGxU1ZvlvJ9XPHJBu71LtG2Dvhuy9OfsS9bIQKysrBAUFITk5WbtNo9EgOTkZYWFhJrNPIlPjbKs06DgiIqlp1hEgmUyGsrIyKJVKCIIAmUyG27dvaw85NefQU53o6GhMmzYNgwYNQkhICJYvX47y8nLtFVxTp05Fly5dEB8fD6B2knNWVpb279euXcPx48fRoUMH9OjRo0n7JDJ3Xk42sJTLUKPRf8pZBsDVXokQMzr9RURkTM2eA9SrVy+dxwMGDNB53NzLbSdMmIDr169j0aJFyM/PR2BgIBITE7WTmHNyciCX/3mgKjc3V+c9ly5diqVLl2LIkCFISUlp0j6JzNm1W3cw+fPDjYYfAIgd5QcLc5wBTURkBM0KQPv27WuVIqKiohAVFaX3ubpQU8fLy6tJE60b2yeRubpcVI5Jnx/GtVt30MWhHWYP8cF/Ui7q3AfI1V6J2FF+GOHvJmKlRESmrVkBaMiQIa1VBxHdx7n8Mkz+72FcL6uCj1N7bHgxFO4O7fC30G5Iyy5GYVklnG1rT3vxyA8RUeOaFYBqamqgVqt1rpgqKCjA6tWrUV5ejtGjR+ORRx4xeJFEUnfqagmmJBzGrQoVfF1t8eWMUHS2rf0+tJDLENbdUeQKiYjMS7MC0MyZM2FlZYU1a9YAAMrKyhAcHIzKykq4ubnho48+wo4dO/D000+3SrFEUnTkcjFeWHsEZVU1CPBwwBeRwXCwsRK7LCIis9asy+B//fVXjBs3Tvt4/fr1UKvVOH/+PE6cOIHo6Gh88MEHBi+SSKp+OX8dU/+bhrKqGoR6d8JXL4Yy/BARGUCzAtC1a9fQs2dP7ePk5GSMGzcO9vb2AIBp06bh9OnThq2QSKJ+PFOIGeuO4o5KjSG9OmNdZAg6WIu+fjERUZvQrACkVCpx584d7eNDhw4hNDRU5/nbt28brjoiiUovkiFq0wlUqzV4yt8Vn04NQjsrC7HLIiJqM5oVgAIDA/Hll18CAH755RcUFBRg6NCh2ucvXrwId3d3w1ZIJDHfHL2KL8/LodYI+MvALvh44gBYWzL8EBEZUrOOpy9atAhPPfUUvvnmG+Tl5WH69Olwc/vzXiPbtm3Dww8/bPAiiaTivwey8fZ3WQBk+FtIV7wztj/kvKSdiMjgmn0foPT0dOzduxeurq4YP368zvOBgYEICQkxaIFEUiAIAj756QI+TPoNADDUXYO3nunD8ENE1EqaPaOyT58+6NOnj97nZs2a9cAFEUmNIAhYnHgWa/ZfAgDMf7IHvMrPNntZGSIiarpmBaCff/65SeMee+yxFhVDJDUajYBFOzOx4VAOAGDhyD6Y9pAHdu8+K3JlRERtW7MC0OOPP679v9KG1uOSyWRQq9UPXhlRG1ej1uCf357E1oxrkMmA957th4khnlCpVGKXRkTU5jUrAHXs2BG2traYPn06pkyZAicnp9aqi6hNq67RYN6mY9iTmQ8LuQzL/hqAMYFdxC6LiEgymnUZfF5eHpYsWYLU1FT069cPM2bMwMGDB2FnZwd7e3vtf0TUsEqVGrO+PIo9mfmwspBj1aSBDD9EREbWrABkZWWFCRMm4IcffsDZs2fRv39/REVFwcPDA//6179QU1PTWnUSmSW1RkDqxRvYcfwaUi/eQMkdFaYlpCHl3HUoFXL8d/ogDO/rKnaZRESS0+L76nt6emLRokWYMmUKZsyYgcWLF+Pvf/87OnXqZMj6iMxWYmYe4nZlIa+kUrtNYSGDSi3A1toSCZHBCPbi9wsRkRiadQSoTlVVFTZu3Ijw8HD4+/vDyckJ33//PcMP0R8SM/MwZ0OGTvgBAJW69uKBqKE9GH6IiETUrCNAaWlpWLt2LTZt2gQvLy9ERkbim2++YfAhuotaIyBuVxb0XydZa93By3jxUR9Y8EaHRESiaFYAeuihh+Dp6YlXXnkFQUFBAIADBw7UGzd69GjDVEdkhtKyi+sd+blXXkkl0rKLEdbd0UhVERHR3Zo9BygnJwdvv/12g8/zPkAkdYVljYef5o4jIiLDa1YA0mg09x1TUVHR4mKI2gJnW6VBxxERkeG1aBK0PlVVVVi2bBl8fHwMtUsiszTQ0wHWlg1/a8kAuNkrEeLNuXNERGJpVgCqqqpCTEwMBg0ahMGDB2P79u0AgISEBHh7e+Ojjz7Cq6++2hp1EpkFQRDw1q4sVNXoP1paN+U5dpQfJ0ATEYmoWafAFi1ahDVr1iA8PBwHDx7E+PHjERkZiUOHDmHZsmUYP348LCwsWqtWIpP30Y/n8XVaDuQyYOaj3th5Ik9nQrSrvRKxo/wwwt9NxCqJiKhZAWjLli1Yv349Ro8ejczMTPTv3x81NTU4ceKEdpFUIqn6MvUy/i/5PADg32P8MfmhbvjniD5Iyy5GYVklnG1rT3vxyA8RkfiaFYCuXr2qvfzd398f1tbWePXVVxl+SPJ2n8rDop2nAQDzw3ti8kPdAAAWchkvdSciMkHNmgOkVqthZWWlfWxpaYkOHToYvCgic3LwYhHmbzoOQQAmhXpi3pM9xS6JiIjuo1lHgARBwPTp02FtbQ0AqKysxOzZs9G+fXudcVu3bjVchUQmLPNaCWatT0e1WoMRfV3x7zH+PCJKRGQGmhWApk2bpvN48uTJBi2GyJzk3KjA9LVHcLuqBqHenbD8+UDO7yEiMhPNCkBr165trTqIzMr1sipMSTiMottV6ONmh8+mDYJSwSsgiYjMhcFuhEgkFberahC5Lg1XblSga8d2+CIyGHZKhdhlERFRMzAAETVDdY0Gs79MR+a1Uji2t8KXM0LhbMclLYiIzA0DEFETaTQC/r7lBA5cKIKNlQXWRgbD26n9/V9IREQmhwGIqAkEQcC/v8vCrhO5UFjIsGZKEPp3dRC7LCIiaiEGIKImWLX/ItYdvAwAWDo+AI/27CxuQURE9EAYgIju45ujv+P9xHMAgEXP+GFMYBeRKyIiogfFAETUiB+zChCz9RQAYPaQ7njhEW+RKyIiIkNgACJqQPqVYszdmAG1RsC4gV3x2ojeYpdEREQGwgBEpMdvBWV4Yd1RVNVoMNTXGYvH9eMSF0REbQgDENE9cm/dwbSENJTcUWGApwNW/m0gFBb8ViEiakv4U53oLjfLqzE1IQ15JZXo4dwBCdOC0c6KS1wQEbU1DEBEf6iorsELXxzBhcLbcLNXYv0LIejY3krssoiIqBWYRABauXIlvLy8oFQqERoairS0tEbHb9myBb6+vlAqlejXrx92796t8/zt27cRFRWFrl27ol27dvDz88Pq1atbswUyQ2qNgNSLN7Dj+DUcOH8dc7/KwLGcW7Bvp8AXL4TA3aGd2CUSEVEradZq8K1h8+bNiI6OxurVqxEaGorly5cjIiIC586dg7Ozc73xBw8exMSJExEfH49nnnkGGzduxNixY5GRkQF/f38AQHR0NH766Sds2LABXl5e2Lt3L1566SW4u7tj9OjRxm6RTFBiZh7idmUhr6RSZ7vCQoaE6YPQy8VWpMqIiMgYRD8CtGzZMsycORORkZHaIzU2NjZISEjQO37FihUYMWIEFixYgD59+uDtt9/GwIED8cknn2jHHDx4ENOmTcPjjz8OLy8vzJo1CwEBAfc9skTSkJiZhzkbMuqFHwBQqQVcL6sSoSoiIjImUY8AVVdXIz09HTExMdptcrkc4eHhSE1N1fua1NRUREdH62yLiIjA9u3btY8HDx6MnTt34oUXXoC7uztSUlLw22+/4aOPPtK7z6qqKlRV/flLr7S0FACgUqmgUqla2p5B1L2/2HWIoTV6V2sEvLXzNIQGnpcBiNt1Go/3dISFXJzL3vmZs3cpkWrfAHu/+09D77cpRA1ARUVFUKvVcHFx0dnu4uKCs2fP6n1Nfn6+3vH5+fnaxx9//DFmzZqFrl27wtLSEnK5HJ999hkee+wxvfuMj49HXFxcve179+6FjY1Nc9tqFUlJSWKXIBpD9n6+RIb80oav6hIA5JVU4ZPNiehp31BMMg5+5tIk1d6l2jfA3g2poqKiyWNFnwPUGj7++GMcOnQIO3fuRLdu3fDzzz9j7ty5cHd3R3h4eL3xMTExOkeVSktL4eHhgeHDh8POzs6YpdejUqmQlJSEYcOGQaFQiFqLsbVG77tO5gFZp+47zqdvIJ7u72aQ92wufubsXUq9S7VvgL23Ru91Z3CaQtQA5OTkBAsLCxQUFOhsLygogKurq97XuLq6Njr+zp07eOONN7Bt2zaMHDkSANC/f38cP34cS5cu1RuArK2tYW1tXW+7QqEwmS9KU6rF2AzZu5tD+yaPE/vfm585e5cSqfYNsHdD9t6cfYk6CdrKygpBQUFITk7WbtNoNEhOTkZYWJje14SFhemMB2oPodWNr5u3I5frtmZhYQGNRmPgDsjchHh3gq2y4dwvA+Bmr0SIdyfjFUVEREYn+imw6OhoTJs2DYMGDUJISAiWL1+O8vJyREZGAgCmTp2KLl26ID4+HgAwb948DBkyBB9++CFGjhyJTZs24ejRo/j0008BAHZ2dhgyZAgWLFiAdu3aoVu3bti/fz/Wr1+PZcuWidYnmYas3FJUVNfofa5uynPsKD/RJkATEZFxiB6AJkyYgOvXr2PRokXIz89HYGAgEhMTtROdc3JydI7mDB48GBs3bsTChQvxxhtvoGfPnti+fbv2HkAAsGnTJsTExGDSpEkoLi5Gt27d8O6772L27NlG749Mx+2qGrz8dQbUGiDQwx75pVXIv+tSeFd7JWJH+WGEvzhzf4iIyHhED0AAEBUVhaioKL3PpaSk1Ns2fvx4jB8/vsH9ubq6Yu3atYYqj9qIRdszcflGBdztlVgXGQJbpQJp2cUoLKuEs23taS8e+SEikgaTCEBErW1rxlVsPXYNchmwYuIAONjUrvEV1t1R5MqIiEgMot8Jmqi1ZReV483tmQCAeU/2QrAXJzgTEUkdAxC1adU1Grzy9TGUV6sR4t0JUUN7iF0SERGZAAYgatM++OEsTl0rgYONAiueD+QcHyIiAsAARG1YyrlCfPZLNgDg/XH94WbfTuSKiIjIVDAAUZtUWFaJf2w5AQCYFtYNw/vqv7M4ERFJEwMQtTkajYDozSdQdLsavq62iHm6j9glERGRiWEAojbn018u4cCFIigVcnzytwFQKhpe/Z2IiKSJAYjalGM5N7H0h3MAgLdG9UUPZ1uRKyIiIlPEAERtRmmlCq9sOoYajYCR/d0wIdhD7JKIiMhEMQBRmyAIAhZuy8TvxXfQxaEd3nu2H2QyXvJORET6MQBRm7Al/Sp2nsiFhVyG/5s4APbtFGKXREREJowBiMzexeu3EbvjNAAgelgvBHXrKHJFRERk6hiAyKxV1ajx8sZjuKNSY3B3R8we0l3skoiIyAwwAJFZW7znLLLyStGpvRU+msClLoiIqGkYgMhsJZ8pwNpfLwMAlo7vDxc7pbgFERGR2WAAIrOUX/LnUhcvPOyNob4uIldERETmhAGIzI5aI+DVzcdxs0KFvu52eO2p3mKXREREZoYBiMzOqpQLSL10AzZWFvh44gBYW3KpCyIiah4GIDIr6VeK8dGP5wEA/x7jD5/OHUSuiIiIzBEDEJmNkjsqvPL1cag1AsYEumPcwC5il0RERGaKAYjMgiAIiNl6Etdu3YFnJxu8M9afS10QEVGLMQCRWdh05HfsPpUPyz+WurBVcqkLIiJqOUuxCyDSR60RcDi7GOlFMtzJuIa3dmUBABZE9Eagh4O4xRERkdljACKTk5iZh7hdWcgrqQRgAZyvXeerj5stZj7qI25xRETUJvAUGJmUxMw8zNmQ8Uf40XUmrwx7s/JFqIqIiNoaBiAyGWqNgLhdWRAaeF4GIG5XFtSahkYQERE1DQMQmYy07GK9R37qCADySiqRll1svKKIiKhNYgAik1FY1nD4ack4IiKihjAAkclwtm3aau5NHUdERNQQBiAyGSHenWCrbPjCRBkAN3slQrw7Ga8oIiJqkxiAyGQcunQDtytr9D5Xd8/n2FF+sJDzDtBERPRgGIDIJPxeXIGojRkQADzk7QhXe93TXK72SqyaPBAj/N3EKZCIiNoU3giRRHenWo3/92U6blao0K+LPda9EAyFhRypFwqx95fDGP5oKMJ6OPPIDxERGQwDEIlKEAS8vvUksvJK4djeCmumBEGpsAAAhHp3wo0zAkK9OzH8EBGRQfEUGInqvweyseN4LizlMqycNBDuDu3ELomIiCSAAYhE8+uFIry3+wwAYOHIPnjIx1HkioiISCoYgEgUdZOeNQIwbmBXTBvsJXZJREQkIQxAZHT3Tnp+91l/yGSc40NERMbDAERG1dikZyIiImNhACKj4qRnIiIyBQxAZDSc9ExERKbCJALQypUr4eXlBaVSidDQUKSlpTU6fsuWLfD19YVSqUS/fv2we/fuemPOnDmD0aNHw97eHu3bt0dwcDBycnJaqwW6D056JiIiUyJ6ANq8eTOio6MRGxuLjIwMBAQEICIiAoWFhXrHHzx4EBMnTsSMGTNw7NgxjB07FmPHjkVmZqZ2zMWLF/HII4/A19cXKSkpOHnyJN58800olVxFXAyc9ExERKZG9AC0bNkyzJw5E5GRkfDz88Pq1athY2ODhIQEveNXrFiBESNGYMGCBejTpw/efvttDBw4EJ988ol2zL/+9S88/fTTeP/99zFgwAB0794do0ePhrOzs7Haoj9w0jMREZkiUQNQdXU10tPTER4ert0ml8sRHh6O1NRUva9JTU3VGQ8AERER2vEajQbff/89evXqhYiICDg7OyM0NBTbt29vtT6oYZz0TEREpkjUtcCKioqgVqvh4uKis93FxQVnz57V+5r8/Hy94/Pz8wEAhYWFuH37NhYvXox33nkHS5YsQWJiIv7yl79g3759GDJkSL19VlVVoaqqSvu4tLQUAKBSqaBSqR6oxwdV9/5i19ESBy/e0E56jnmqN4I87JrVhzn3/iCk2jfA3u/+Uyqk2jfA3u/+09D7bYo2txiqRqMBAIwZMwavvvoqACAwMBAHDx7E6tWr9Qag+Ph4xMXF1du+d+9e2NjYtG7BTZSUlCR2Cc1yoxL48JQFNIIMwZ01cLyRid27M+//Qj3MrXdDkWrfAHuXIqn2DbB3Q6qoqGjyWFEDkJOTEywsLFBQUKCzvaCgAK6urnpf4+rq2uh4JycnWFpaws/PT2dMnz59cODAAb37jImJQXR0tPZxaWkpPDw8MHz4cNjZ2TW7L0NSqVRISkrCsGHDoFAoRK2lqe5UqzHhszSU15TB390OCS8Gt2jejzn2bghS7Rtg71LsXap9A+y9NXqvO4PTFKIGICsrKwQFBSE5ORljx44FUHsEJzk5GVFRUXpfExYWhuTkZMyfP1+7LSkpCWFhYdp9BgcH49y5czqv++2339CtWze9+7S2toa1tXW97QqFwmS+KE2plsYIgoA3v83EmfwyOLa3wqdTB8HW5sGuvjOX3g1Nqn0D7F2KvUu1b4C9G7L35uxL9FNg0dHRmDZtGgYNGoSQkBAsX74c5eXliIyMBABMnToVXbp0QXx8PABg3rx5GDJkCD788EOMHDkSmzZtwtGjR/Hpp59q97lgwQJMmDABjz32GJ544gkkJiZi165dSElJEaNFSeGkZyIiMgeiB6AJEybg+vXrWLRoEfLz8xEYGIjExETtROecnBzI5X9erDZ48GBs3LgRCxcuxBtvvIGePXti+/bt8Pf314559tlnsXr1asTHx+OVV15B79698e233+KRRx4xen9ScpB3eiYiIjMhegACgKioqAZPeek7ajN+/HiMHz++0X2+8MILeOGFFwxRHjXB78UVmPvHnZ7/MrAL7/RMREQmTfQbIZL5u/dOz+892493eiYiIpNmEkeAyLyoNQLSsotRWFYJZ1trfJ2Wwzs9ExGRWWEAomZJzMxD3K4s5JVU6myXy8BJz0REZDYYgKjJEjPzMGdDBgQ9z2kE4FZFtdFrIiIiagnOAaImUWsExO3K0ht+AEAGIG5XFtSahkYQERGZDgYgapK07OJ6p73uJgDIK6lEWnax8YoiIiJqIQYgapLCsobDT0vGERERiYkBiJrE2bZpy1k0dRwREZGYGICoSUK8O6GjTcNrrMgAuNkrEeLdyXhFERERtRADEDXJ+cIyVFSr9T5Xd8vD2FF+sJDzBohERGT6GIDovorLqzFz/VFU1WjQ26UDXO10T3O52iuxavJAjPB3E6lCIiKi5uF9gKhRKrUGL32Vjt+L78Czkw02zQqDXTvFXXeCrj3txSM/RERkThiAqFFxu07j0KVidLC2xOfTBqFjeysAQFh3rvRORETmi6fAqEFfHrqCDYdyIJMByycEopeLrdglERERGQQDEOmVevEG4naeBgAsiOiNcD8XkSsiIiIyHAYgquf34gq89FU6ajQCRge4Y86Q7mKXREREZFAMQKTjdlUNXvziKG5WqNCviz3ef64/ZDJOcCYioraFAYi0NBoB0ZuP41xBGTrbWuPTqUFQKizELouIiMjgGIBI66Mff8PerAJYWcqxZkoQ3OzbiV0SERFRq2AAIgDArhO5+PinCwCA+Gf7YaBnR5ErIiIiaj0MQITMayVY8L8TAIBZj/lgXFBXkSsiIiJqXQxAEne9rAoz1x9FpUqDIb0647URvmKXRERE1OoYgCSsqkaN2RvSkVdSCZ/O7fF/EwdwSQsiIpIEBiCJEgQBC7dlIv3KTdgqLfH51EGwb6cQuywiIiKjYACSqIRfL2NL+lXIZcDKvw2ET+cOYpdERERkNAxAEvTzb9fx7vdZAIB/jfTDY706i1wRERGRcTEAScyl67cRtTEDGgEYH9QVLzzsJXZJRERERscAJCGllSq8uP4oSitrMNDTAe88689lLoiISJIYgCRCrRHwytfHcOl6OdzslVg9JQjWllzmgoiIpIkBSCLeTzyLlHPXoVTI8dnUQXC2VYpdEhERkWgYgCTg2/SrWPPzJQDAB88FwL+LvcgVERERiYsBqI3LyLmJmK2nAAAvD+2BUQHuIldEREQkPkuxCyDDUmsEpGUXo7CsEpZyOWJ3ZqJarcEwPxe8Gt5L7PKIiIhMAgNQG5KYmYe4XVnIK6nU2e5ur8RHEwIh5zIXREREAHgKrM1IzMzDnA0Z9cIPAOSWVOLA+esiVEVERGSaGIDaALVGQNyuLAgNPC8DELcrC2pNQyOIiIikhQGoDUjLLtZ75KeOACCvpBJp2cXGK4qIiMiEMQC1AYVlDYeflowjIiJq6xiA2oCm3tSQNz8kIiKqxQDUBoR4d0J7q4aXtZABcLNXIsS7k/GKIiIiMmEMQG1A8pkClFer9T5Xd+F77Cg/WPAyeCIiIgAMQGYv50YF/r7lBADgSV9nuNnrnuZytVdi1eSBGOHvJkZ5REREJok3QjRjVTVqzN2YgbLKGgz0dMDqKUGQy2TaO0E729ae9uKRHyIiIl0mcQRo5cqV8PLyglKpRGhoKNLS0hodv2XLFvj6+kKpVKJfv37YvXt3g2Nnz54NmUyG5cuXG7hq8b37/RmculaCjjYKfPK3gVBYyGEhlyGsuyPGBHZBWHdHhh8iIiI9RA9AmzdvRnR0NGJjY5GRkYGAgABERESgsLBQ7/iDBw9i4sSJmDFjBo4dO4axY8di7NixyMzMrDd227ZtOHToENzd294CoLtO5GJ96hUAwLIJgXB3aCdyRUREROZD9AC0bNkyzJw5E5GRkfDz88Pq1athY2ODhIQEveNXrFiBESNGYMGCBejTpw/efvttDBw4EJ988onOuGvXruHll1/GV199BYVCYYxWjObS9dt4/duTAIC5T3THE72dRa6IiIjIvIg6B6i6uhrp6emIiYnRbpPL5QgPD0dqaqre16SmpiI6OlpnW0REBLZv3659rNFoMGXKFCxYsAB9+/a9bx1VVVWoqqrSPi4tLQUAqFQqqFSq5rRkcHXvX/dnpUqNORvSUV6tRohXR0QN8Ra9xtZyb+9SIdW+AfZ+959SIdW+AfZ+95+G3m9TiBqAioqKoFar4eLiorPdxcUFZ8+e1fua/Px8vePz8/O1j5csWQJLS0u88sorTaojPj4ecXFx9bbv3bsXNjY2TdpHa0tKSgIAbLwgx7nrcnRQCHjG8Tr2/pAocmWtr653qZFq3wB7lyKp9g2wd0OqqKho8tg2dxVYeno6VqxYgYyMDMhkTZsAHBMTo3NUqbS0FB4eHhg+fDjs7Oxaq9QmUalUSEpKwrBhw7DzVCEOp56GTAb8Z/IghPk4ilpba7u797Z2GrMxUu0bYO9S7F2qfQPsvTV6rzuD0xSiBiAnJydYWFigoKBAZ3tBQQFcXV31vsbV1bXR8b/88gsKCwvh6empfV6tVuPvf/87li9fjsuXL9fbp7W1NaytrettVygUJvNFmV1cibe+OwMAeDW8Fx7rrf/fpy0ypc/BmKTaN8Depdi7VPsG2Lshe2/OvkSdBG1lZYWgoCAkJydrt2k0GiQnJyMsLEzva8LCwnTGA7WH0OrGT5kyBSdPnsTx48e1/7m7u2PBggX44YcfWq+ZVlSlBl7edAKVKg0e7emEqCd6iF0SERGRWRP9FFh0dDSmTZuGQYMGISQkBMuXL0d5eTkiIyMBAFOnTkWXLl0QHx8PAJg3bx6GDBmCDz/8ECNHjsSmTZtw9OhRfPrppwAAR0dHODrqnhpSKBRwdXVF7969jducAQiCgM2X5LhUVAFXOyWWTwiEnPf2ISIieiCiB6AJEybg+vXrWLRoEfLz8xEYGIjExETtROecnBzI5X8eqBo8eDA2btyIhQsX4o033kDPnj2xfft2+Pv7i9VCq9p09CrSi2pvcPjx3wbAsUP9U3VERETUPKIHIACIiopCVFSU3udSUlLqbRs/fjzGjx/f5P3rm/djDjKvleDt72uvhvvHsJ4I9uJq7kRERIYg+o0QSb/SShVe+ioDKrUA/44azHi4m9glERERtRkMQCZIEAT8c8tJ5BRXoKuDEpN6aJp8ST8RERHdHwOQCUr49TIST+dDYSHDigkBsDGJE5VERERtBwOQicnIuYn43bX3+1k40g/9u9qLXBEREVHbwwBkQm6WVyPqqwzUaASM7OeGqWGc90NERNQaGIBMhEYjIPqb48gtqYSXow0Wj+vHeT9ERESthAHIRKz++SL2nbsOK0s5/jMpCLZKad4WnYiIyBgYgEzAoUs3sPSHcwCAf4/uCz93cRdgJSIiausYgER2vawKr3x9DBoB+MuALpgQ7CF2SURERG0eA5CI1BoB8zcfQ2FZFXo6d8A7z/pz3g8REZERMACJ6P+Sz+PXCzfQTmGBVZMHwsaKN/whIiIyBv7GNSK1RkBadjEKyyqRX1KJFcnnAQDv/cUfPZxtRa6OiIhIOhiAjCQxMw9xu7KQV1Kps/2RHk54dkBXkaoiIiKSJp4CM4LEzDzM2ZBRL/wAwK8XipCYmSdCVURERNLFANTK1BoBcbuyIDQyJm5XFtSaxkYQERGRITEAtbK07GK9R37qCADySiqRll1svKKIiIgkjgGolRWWNRx+WjKOiIiIHhwDUCtztlUadBwRERE9OAagVhbi3Qlu9ko0dHtDGQA3eyVCvDsZsywiIiJJYwBqZRZyGWJH+QFAvRBU9zh2lB8s5LwDNBERkbEwABnBCH83rJo8EK72uqe5XO2VWDV5IEb4u4lUGRERkTTxRohGMsLfDcP8XLV3gna2rT3txSM/RERExscAZEQWchnCujuKXQYREZHk8RQYERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDu8ErYcgCACA0tJSkSsBVCoVKioqUFpaCoVCIXY5RiXV3qXaN8Depdi7VPsG2Htr9F73e7vu93hjGID0KCsrAwB4eHiIXAkRERE1V1lZGezt7RsdIxOaEpMkRqPRIDc3F7a2tpDJxF2stLS0FB4eHvj9999hZ2cnai3GJtXepdo3wN6l2LtU+wbYe2v0LggCysrK4O7uDrm88Vk+PAKkh1wuR9euXcUuQ4ednZ3kvkHqSLV3qfYNsHcp9i7VvgH2buje73fkpw4nQRMREZHkMAARERGR5DAAmThra2vExsbC2tpa7FKMTqq9S7VvgL1LsXep9g2wd7F75yRoIiIikhweASIiIiLJYQAiIiIiyWEAIiIiIslhACIiIiLJYQASUXx8PIKDg2FrawtnZ2eMHTsW586da/Q169atg0wm0/lPqVQaqWLDeeutt+r14evr2+hrtmzZAl9fXyiVSvTr1w+7d+82UrWG5eXlVa93mUyGuXPn6h1vrp/5zz//jFGjRsHd3R0ymQzbt2/XeV4QBCxatAhubm5o164dwsPDcf78+fvud+XKlfDy8oJSqURoaCjS0tJaqYOWa6x3lUqF1157Df369UP79u3h7u6OqVOnIjc3t9F9tuR7Rgz3+9ynT59er48RI0bcd7+m/rnfr2993/MymQwffPBBg/s0h8+8Kb/HKisrMXfuXDg6OqJDhw4YN24cCgoKGt1vS38+NAcDkIj279+PuXPn4tChQ0hKSoJKpcLw4cNRXl7e6Ovs7OyQl5en/e/KlStGqtiw+vbtq9PHgQMHGhx78OBBTJw4ETNmzMCxY8cwduxYjB07FpmZmUas2DCOHDmi03dSUhIAYPz48Q2+xhw/8/LycgQEBGDlypV6n3///ffxf//3f1i9ejUOHz6M9u3bIyIiApWVlQ3uc/PmzYiOjkZsbCwyMjIQEBCAiIgIFBYWtlYbLdJY7xUVFcjIyMCbb76JjIwMbN26FefOncPo0aPvu9/mfM+I5X6fOwCMGDFCp4+vv/660X2aw+d+v77v7jcvLw8JCQmQyWQYN25co/s19c+8Kb/HXn31VezatQtbtmzB/v37kZubi7/85S+N7rclPx+aTSCTUVhYKAAQ9u/f3+CYtWvXCvb29sYrqpXExsYKAQEBTR7/17/+VRg5cqTOttDQUOH//b//Z+DKjG/evHlC9+7dBY1Go/f5tvCZAxC2bdumfazRaARXV1fhgw8+0G67deuWYG1tLXz99dcN7ickJESYO3eu9rFarRbc3d2F+Pj4VqnbEO7tXZ+0tDQBgHDlypUGxzT3e8YU6Ot92rRpwpgxY5q1H3P73JvymY8ZM0YYOnRoo2PM8TO/9/fYrVu3BIVCIWzZskU75syZMwIAITU1Ve8+Wvrzobl4BMiElJSUAAA6derU6Ljbt2+jW7du8PDwwJgxY3D69GljlGdw58+fh7u7O3x8fDBp0iTk5OQ0ODY1NRXh4eE62yIiIpCamtraZbaq6upqbNiwAS+88EKjC++2lc+8TnZ2NvLz83U+U3t7e4SGhjb4mVZXVyM9PV3nNXK5HOHh4Wb/dVBSUgKZTAYHB4dGxzXne8aUpaSkwNnZGb1798acOXNw48aNBse2xc+9oKAA33//PWbMmHHfseb2md/7eyw9PR0qlUrn8/P19YWnp2eDn19Lfj60BAOQidBoNJg/fz4efvhh+Pv7Nziud+/eSEhIwI4dO7BhwwZoNBoMHjwYV69eNWK1Dy40NBTr1q1DYmIiVq1ahezsbDz66KMoKyvTOz4/Px8uLi4621xcXJCfn2+MclvN9u3bcevWLUyfPr3BMW3lM79b3efWnM+0qKgIarW6zX0dVFZW4rXXXsPEiRMbXRSyud8zpmrEiBFYv349kpOTsWTJEuzfvx9PPfUU1Gq13vFt8XP/4osvYGtre9/TQOb2mev7PZafnw8rK6t64b6xz68lPx9agqvBm4i5c+ciMzPzvud3w8LCEBYWpn08ePBg9OnTB2vWrMHbb7/d2mUazFNPPaX9e//+/REaGopu3brhm2++adL/FbUV//3vf/HUU0/B3d29wTFt5TOn+lQqFf76179CEASsWrWq0bFt5Xvm+eef1/69X79+6N+/P7p3746UlBQ8+eSTIlZmPAkJCZg0adJ9L2Ywt8+8qb/HTAWPAJmAqKgofPfdd9i3bx+6du3arNcqFAoMGDAAFy5caKXqjMPBwQG9evVqsA9XV9d6Vw0UFBTA1dXVGOW1iitXruDHH3/Eiy++2KzXtYXPvO5za85n6uTkBAsLizbzdVAXfq5cuYKkpKRGj/7oc7/vGXPh4+MDJyenBvtoa5/7L7/8gnPnzjX7+x4w7c+8od9jrq6uqK6uxq1bt3TGN/b5teTnQ0swAIlIEARERUVh27Zt+Omnn+Dt7d3sfajVapw6dQpubm6tUKHx3L59GxcvXmywj7CwMCQnJ+tsS0pK0jkyYm7Wrl0LZ2dnjBw5slmvawufube3N1xdXXU+09LSUhw+fLjBz9TKygpBQUE6r9FoNEhOTja7r4O68HP+/Hn8+OOPcHR0bPY+7vc9Yy6uXr2KGzduNNhHW/rcgdqjvkFBQQgICGj2a03xM7/f77GgoCAoFAqdz+/cuXPIyclp8PNryc+HlhZPIpkzZ45gb28vpKSkCHl5edr/KioqtGOmTJkivP7669rHcXFxwg8//CBcvHhRSE9PF55//nlBqVQKp0+fFqOFFvv73/8upKSkCNnZ2cKvv/4qhIeHC05OTkJhYaEgCPX7/vXXXwVLS0th6dKlwpkzZ4TY2FhBoVAIp06dEquFB6JWqwVPT0/htddeq/dcW/nMy8rKhGPHjgnHjh0TAAjLli0Tjh07pr3SafHixYKDg4OwY8cO4eTJk8KYMWMEb29v4c6dO9p9DB06VPj444+1jzdt2iRYW1sL69atE7KysoRZs2YJDg4OQn5+vtH7a0xjvVdXVwujR48WunbtKhw/flzne7+qqkq7j3t7v9/3jKlorPeysjLhH//4h5CamipkZ2cLP/74ozBw4EChZ8+eQmVlpXYf5vi53+/rXRAEoaSkRLCxsRFWrVqldx/m+Jk35ffY7NmzBU9PT+Gnn34Sjh49KoSFhQlhYWE6++ndu7ewdetW7eOm/Hx4UAxAIgKg97+1a9dqxwwZMkSYNm2a9vH8+fMFT09PwcrKSnBxcRGefvppISMjw/jFP6AJEyYIbm5ugpWVldClSxdhwoQJwoULF7TP39u3IAjCN998I/Tq1UuwsrIS+vbtK3z//fdGrtpwfvjhBwGAcO7cuXrPtZXPfN++fXq/vut602g0wptvvim4uLgI1tbWwpNPPlnv36Nbt25CbGyszraPP/5Y++8REhIiHDp0yEgdNV1jvWdnZzf4vb9v3z7tPu7t/X7fM6aisd4rKiqE4cOHC507dxYUCoXQrVs3YebMmfWCjDl+7vf7ehcEQVizZo3Qrl074datW3r3YY6feVN+j925c0d46aWXhI4dOwo2NjbCs88+K+Tl5dXbz92vacrPhwcl++ONiYiIiCSDc4CIiIhIchiAiIiISHIYgIiIiEhyGICIiIhIchiAiIiISHIYgIiIiEhyGICIiIhIchiAiKjNmT59OsaOHSt2GURkwrgaPBGZFZlM1ujzsbGxWLFiBXiPVyJqDAMQEZmVvLw87d83b96MRYsW4dy5c9ptHTp0QIcOHcQojYjMCE+BEZFZcXV11f5nb28PmUyms61Dhw71ToE9/vjjePnllzF//nx07NgRLi4u+Oyzz1BeXo7IyEjY2tqiR48e2LNnj857ZWZm4qmnnkKHDh3g4uKCKVOmoKioyMgdE1FrYAAiIkn44osv4OTkhLS0NLz88suYM2cOxo8fj8GDByMjIwPDhw/HlClTUFFRAQC4desWhg4digEDBuDo0aNITExEQUEB/vrXv4rcCREZAgMQEUlCQEAAFi5ciJ49eyImJgZKpRJOTk6YOXMmevbsiUWLFuHGjRs4efIkAOCTTz7BgAED8N5778HX1xcDBgxAQkIC9u3bh99++03kbojoQXEOEBFJQv/+/bV/t7CwgKOjI/r166fd5uLiAgAoLCwEAJw4cQL79u3TO5/o4sWL6NWrVytXTEStiQGIiCRBoVDoPJbJZDrb6q4u02g0AIDbt29j1KhRWLJkSb19ubm5tWKlRGQMDEBERHoMHDgQ3377Lby8vGBpyR+VRG0N5wAREekxd+5cFBcXY+LEiThy5AguXryIH374AZGRkVCr1WKXR0QPiAGIiEgPd3d3/Prrr1Cr1Rg+fDj69euH+fPnw8HBAXI5f3QSmTuZwNulEhERkcTwf2OIiIhIchiAiIiISHIYgIiIiEhyGICIiIhIchiAiIiISHIYgIiIiEhyGICIiIhIchiAiIiISHIYgIiIiEhyGICIiIhIchiAiIiISHIYgIiIiEhy/j+Aw0y6XkBaxAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def RMSE(surv_hat, surv):\n",
        "  rmse = []\n",
        "  for time_point in range(len(surv[0])):\n",
        "    diff = 0\n",
        "    for patient in range(len(surv_hat)):\n",
        "      diff += (surv[patient, time_point] - surv_hat[patient, time_point])**2\n",
        "    diff = diff / len(surv_hat)\n",
        "    rmse.append(np.sqrt(diff))\n",
        "\n",
        "  return rmse\n",
        "\n",
        "rmse_data = RMSE(surv0, te_hazs)"
      ],
      "metadata": {
        "id": "XtagyJL47wPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jO4qeDtt7HXY"
      },
      "outputs": [],
      "source": [
        "surv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToEhevZf6h86",
        "outputId": "11d5b7d8-2b5d-45b9-82fb-5e3e413e2c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: SurvITE/ (stored 0%)\n",
            "  adding: SurvITE/surviTE/ (stored 0%)\n",
            "  adding: SurvITE/surviTE/model_wassersteinnoweight.index (deflated 77%)\n",
            "  adding: SurvITE/surviTE/model_wassersteinnoweight.meta (deflated 92%)\n",
            "  adding: SurvITE/surviTE/model_wassersteinnoweight.data-00000-of-00001 (deflated 62%)\n",
            "  adding: SurvITE/surviTE/checkpoint (deflated 44%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r ./SurvITE.zip ./SurvITE/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yaFvIS257RG5"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"SurvITE.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}